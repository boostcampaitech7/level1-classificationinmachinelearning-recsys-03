{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 호출\n",
    "data_path: str = \"/data/ephemeral/home/BTC/data\"\n",
    "train_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"train.csv\")).assign(_type=\"train\") # train 에는 _type = train \n",
    "test_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"test.csv\")).assign(_type=\"test\") # test 에는 _type = test\n",
    "submission_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"test.csv\")) # ID, target 열만 가진 데이터 미리 호출\n",
    "df: pd.DataFrame = pd.concat([train_df, test_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:03<00:00, 28.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# HOURLY_ 로 시작하는 .csv 파일 이름을 file_names 에 할딩\n",
    "file_names: List[str] = [\n",
    "    f for f in os.listdir(data_path) if f.startswith(\"HOURLY_\") and f.endswith(\".csv\")\n",
    "]\n",
    "\n",
    "# 파일명 : 데이터프레임으로 딕셔너리 형태로 저장\n",
    "file_dict: Dict[str, pd.DataFrame] = {\n",
    "    f.replace(\".csv\", \"\"): pd.read_csv(os.path.join(data_path, f)) for f in file_names\n",
    "}\n",
    "\n",
    "for _file_name, _df in tqdm(file_dict.items()):\n",
    "    # 열 이름 중복 방지를 위해 {_file_name.lower()}_{col.lower()}로 변경, datetime 열을 ID로 변경\n",
    "    _rename_rule = {\n",
    "        col: f\"{_file_name.lower()}_{col.lower()}\" if col != \"datetime\" else \"ID\"\n",
    "        for col in _df.columns\n",
    "    }\n",
    "    _df = _df.rename(_rename_rule, axis=1)\n",
    "    df = df.merge(_df, on=\"ID\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA (Explanatory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11552, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델에 사용할 컬럼, 컬럼의 rename rule을 미리 할당함\n",
    "cols_dict: Dict[str, str] = {\n",
    "    \"ID\": \"ID\",\n",
    "    \"target\": \"target\",\n",
    "    \"_type\": \"_type\",\n",
    "    \"hourly_market-data_price-ohlcv_all_exchange_spot_btc_usd_close\": \"close\",\n",
    "    \"hourly_market-data_open-interest_all_exchange_all_symbol_open_interest\": \"open_interest\",\n",
    "    \"hourly_network-data_difficulty_difficulty\": \"difficulty\",\n",
    "    \"hourly_network-data_supply_supply_total\": \"supply_total\",\n",
    "    \"hourly_network-data_utxo-count_utxo_count\": \"utxo_count\"\n",
    "}\n",
    "df = df[cols_dict.keys()].rename(cols_dict, axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continuous 열을 따로 할당해둠\n",
    "conti_cols: List[str] = [\n",
    "    \"close\",\n",
    "    \"open_interest\",\n",
    "    \"difficulty\",\n",
    "    \"supply_total\",\n",
    "    \"utxo_count\"\n",
    "]\n",
    "\n",
    "# 최대 24시간의 shift 피쳐를 계산\n",
    "shift_list = shift_feature(\n",
    "    df=df, conti_cols=conti_cols, intervals=[_ for _ in range(1, 24)]\n",
    ")\n",
    "\n",
    "# concat 하여 df 에 할당\n",
    "df = pd.concat([df, pd.concat(shift_list, axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _type에 따라 train, test 분리\n",
    "train_df = df.loc[df[\"_type\"]==\"train\"].drop(columns=[\"_type\"])\n",
    "test_df = df.loc[df[\"_type\"]==\"test\"].drop(columns=[\"_type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_to_class(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"close 변수를 target값으로 변환하는 함수입니다.\n",
    "\n",
    "    Args:\n",
    "        series (pd.Series): 변환을 원하는 close 변수\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: 변환된 target 값\n",
    "    \"\"\"\n",
    "    close = pd.DataFrame()\n",
    "    close['close'] = series\n",
    "    close['close_lag1'] = close['close'].shift(1)\n",
    "    close['close_lag1_percent'] = (close['close'] - close['close_lag1']) / close['close_lag1']\n",
    "    close['class'] = close['close']\n",
    "    for i in range(close.shape[0]):\n",
    "        if close.loc[i, 'close_lag1_percent'] < -0.005:\n",
    "            close.loc[i, 'class'] = 0\n",
    "        elif close.loc[i, 'close_lag1_percent'] < 0:\n",
    "            close.loc[i, 'class'] = 1\n",
    "        elif close.loc[i, 'close_lag1_percent'] < 0.005:\n",
    "            close.loc[i, 'class'] = 2\n",
    "        else:\n",
    "            close.loc[i, 'class'] = 3\n",
    "            \n",
    "    return close['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def model_train(\n",
    "    model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv: int = 5,\n",
    "    metric: str = \"accuracy\"\n",
    ") -> tuple[None, float]:\n",
    "    \"\"\"모델을 불러와 cross validation을 이용해 예측 성능을 확인하는 함수입니다.\n",
    "\n",
    "    Args:\n",
    "        model (Any): 학습을 수행할 모델\n",
    "        X_train (Any): 훈련 데이터 피처\n",
    "        y_train (Any): 훈련 데이터\n",
    "        cv (int): KFold 검정 횟수\n",
    "        metric (str): 성능 지표. accuracy(target), mae, mape mse 중 선택.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    kfold = KFold(n_splits=cv)\n",
    "    score_list = []\n",
    "    for train_index, valid_index in kfold.split(X_train):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_valid, y_valid = X_train.iloc[valid_index], y_train.iloc[valid_index]\n",
    "\n",
    "        valid_target = X_valid[\"target\"]\n",
    "        X_train_fold.drop(\"target\", axis=1, inplace=True)\n",
    "        X_valid.drop(\"target\", axis=1, inplace=True)\n",
    "\n",
    "        # preprocessing\n",
    "        X_train_fold.fillna(X_train_fold.mean(), inplace=True)\n",
    "        y_train_fold.fillna(y_train_fold.mean(), inplace=True)\n",
    "        X_valid.fillna(X_valid.mean(), inplace=True)\n",
    "        y_valid.fillna(y_valid.mean(), inplace=True)  # 이 부분을 mice와 같은 방법으로 조정할 예정. feature selection 등도 여기에서.\n",
    "\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        y_pred = model.predict(X_valid)\n",
    "        score = evaluate(valid_target, y_valid, y_pred, metric=metric)\n",
    "        score_list.append(score)\n",
    "    \n",
    "    return np.mean(score_list)\n",
    "\n",
    "def evaluate(valid_target, y_valid, y_pred, metric):\n",
    "    if metric == 'accuracy':\n",
    "        classes = close_to_class(y_pred)\n",
    "        return accuracy_score(valid_target, classes)\n",
    "    if metric == 'mae':\n",
    "        return mean_absolute_error(y_valid, y_pred)\n",
    "    if metric == \"mse\":\n",
    "        return mean_squared_error(y_valid, y_pred)\n",
    "    if metric == \"mape\":\n",
    "        return mean_absolute_percentage_error(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(): 0.3742009132420091\n",
      "Ridge(random_state=42): 0.373972602739726\n",
      "Lasso(random_state=42): 0.3700913242009133\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df.drop([\"ID\", \"close\"], axis=1)\n",
    "y_train = train_df[\"close\"]\n",
    "X_test = test_df.drop([\"ID\", \"close\"], axis=1)\n",
    "y_test = test_df[\"close\"]\n",
    "X_test.fillna(X_test.mean(), inplace=True)\n",
    "y_test.fillna(y_test.mean(), inplace=True)\n",
    "\n",
    "lr_reg = LinearRegression()\n",
    "ridge_reg = Ridge(random_state=42)\n",
    "lasso_reg = Lasso(random_state=42)\n",
    "lr_score = model_train(lr_reg, X_train, y_train, cv=5, metric=\"accuracy\")\n",
    "ridge_score = model_train(ridge_reg, X_train, y_train, cv=5, metric=\"accuracy\")\n",
    "lasso_score = model_train(lasso_reg, X_train, y_train, cv=5, metric=\"accuracy\")\n",
    "print(f\"{lr_reg}: {lr_score}\")\n",
    "print(f\"{ridge_reg}: {ridge_score}\")\n",
    "print(f\"{lasso_reg}: {lasso_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference (Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr predict\n",
    "y_test_pred = lr_reg.predict(X_test.drop(\"target\", axis=1))\n",
    "y_test_pred_class = close_to_class(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr output\n",
    "submission_df = submission_df.assign(target = y_test_pred_class)\n",
    "submission_df[\"target\"] = submission_df[\"target\"].astype(np.int8)\n",
    "submission_df.to_csv(\"output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb predict\n",
    "y_test_pred = lgb_model.predict(test_df.drop([\"target\", \"ID\"], axis = 1))\n",
    "y_test_pred_class = np.argmax(y_test_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output File Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output file 할당후 save \n",
    "submission_df = submission_df.assign(target = y_test_pred_class)\n",
    "submission_df.to_csv(\"output.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-lecture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
