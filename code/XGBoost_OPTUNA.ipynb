{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:15: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Any, List, Dict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "from data_preprocessing import *\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 호출\n",
    "data_path: str = \"/data/ephemeral/home/BTC/data\"\n",
    "train_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"train.csv\")).assign(_type=\"train\") # train 에는 _type = train \n",
    "test_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"test.csv\")).assign(_type=\"test\") # test 에는 _type = test\n",
    "submission_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"test.csv\")) # ID, target 열만 가진 데이터 미리 호출\n",
    "df: pd.DataFrame = pd.concat([train_df, test_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:03<00:00, 31.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# HOURLY_ 로 시작하는 .csv 파일 이름을 file_names 에 할딩\n",
    "file_names: List[str] = [\n",
    "    f for f in os.listdir(data_path) if f.startswith(\"HOURLY_\") and f.endswith(\".csv\")\n",
    "]\n",
    "\n",
    "# 파일명 : 데이터프레임으로 딕셔너리 형태로 저장\n",
    "file_dict: Dict[str, pd.DataFrame] = {\n",
    "    f.replace(\".csv\", \"\"): pd.read_csv(os.path.join(data_path, f)) for f in file_names\n",
    "}\n",
    "\n",
    "for _file_name, _df in tqdm(file_dict.items()):\n",
    "    # 열 이름 중복 방지를 위해 {_file_name.lower()}_{col.lower()}로 변경, datetime 열을 ID로 변경\n",
    "    _rename_rule = {\n",
    "        col: f\"{_file_name.lower()}_{col.lower()}\" if col != \"datetime\" else \"ID\"\n",
    "        for col in _df.columns\n",
    "    }\n",
    "    _df = _df.rename(_rename_rule, axis=1)\n",
    "    df = df.merge(_df, on=\"ID\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA (Explanatory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11552, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델에 사용할 컬럼, 컬럼의 rename rule을 미리 할당함\n",
    "cols_dict: Dict[str, str] = {\n",
    "    \"ID\": \"ID\",\n",
    "    \"target\": \"target\",\n",
    "    \"_type\" : \"_type\",\n",
    "    \"hourly_market-data_open-interest_all_exchange_all_symbol_open_interest\": \"open_interest\",\n",
    "    \"hourly_market-data_price-ohlcv_all_exchange_spot_btc_usd_close\": \"close\",\n",
    "    \"hourly_network-data_difficulty_difficulty\": \"difficulty\",\n",
    "    \"hourly_network-data_supply_supply_total\": \"supply_total\",\n",
    "    \"hourly_network-data_utxo-count_utxo_count\": \"utxo_count\"\n",
    "}\n",
    "df = df[cols_dict.keys()].rename(cols_dict, axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continuous 열을 따로 할당해둠\n",
    "conti_cols: List[str] = [\n",
    "    \"close\",\n",
    "    \"open_interest\",\n",
    "    \"difficulty\",\n",
    "    \"supply_total\",\n",
    "    \"utxo_count\"\n",
    "]\n",
    "\n",
    "# # 최대 24시간의 shift 피쳐를 계산\n",
    "# shift_list = shift_feature(\n",
    "#     df=df, conti_cols=conti_cols, intervals=[_ for _ in range(1, 24)]\n",
    "# )\n",
    "\n",
    "# # concat 하여 df 에 할당\n",
    "# df = pd.concat([df, pd.concat(shift_list, axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>_type</th>\n",
       "      <th>open_interest</th>\n",
       "      <th>close</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>supply_total</th>\n",
       "      <th>utxo_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6.271344e+09</td>\n",
       "      <td>16536.747967</td>\n",
       "      <td>3.536407e+13</td>\n",
       "      <td>1.924871e+07</td>\n",
       "      <td>83308092.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6.288683e+09</td>\n",
       "      <td>16557.136536</td>\n",
       "      <td>3.536407e+13</td>\n",
       "      <td>1.924874e+07</td>\n",
       "      <td>83314883.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 02:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6.286796e+09</td>\n",
       "      <td>16548.149805</td>\n",
       "      <td>3.536407e+13</td>\n",
       "      <td>1.924879e+07</td>\n",
       "      <td>83314090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 03:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6.284575e+09</td>\n",
       "      <td>16533.632875</td>\n",
       "      <td>3.536407e+13</td>\n",
       "      <td>1.924882e+07</td>\n",
       "      <td>83326258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 04:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6.291582e+09</td>\n",
       "      <td>16524.712159</td>\n",
       "      <td>3.536407e+13</td>\n",
       "      <td>1.924886e+07</td>\n",
       "      <td>83339168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11547</th>\n",
       "      <td>2024-04-26 03:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>1.486836e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.810419e+13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>179820708.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11548</th>\n",
       "      <td>2024-04-26 04:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.810419e+13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>179833897.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11549</th>\n",
       "      <td>2024-04-26 05:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.810419e+13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>179851249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11550</th>\n",
       "      <td>2024-04-26 06:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.810419e+13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>179852452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11551</th>\n",
       "      <td>2024-04-26 07:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.810419e+13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11552 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID  target  _type  open_interest         close  \\\n",
       "0      2023-01-01 00:00:00     2.0  train   6.271344e+09  16536.747967   \n",
       "1      2023-01-01 01:00:00     1.0  train   6.288683e+09  16557.136536   \n",
       "2      2023-01-01 02:00:00     1.0  train   6.286796e+09  16548.149805   \n",
       "3      2023-01-01 03:00:00     1.0  train   6.284575e+09  16533.632875   \n",
       "4      2023-01-01 04:00:00     2.0  train   6.291582e+09  16524.712159   \n",
       "...                    ...     ...    ...            ...           ...   \n",
       "11547  2024-04-26 03:00:00     NaN   test   1.486836e+10           NaN   \n",
       "11548  2024-04-26 04:00:00     NaN   test            NaN           NaN   \n",
       "11549  2024-04-26 05:00:00     NaN   test            NaN           NaN   \n",
       "11550  2024-04-26 06:00:00     NaN   test            NaN           NaN   \n",
       "11551  2024-04-26 07:00:00     NaN   test            NaN           NaN   \n",
       "\n",
       "         difficulty  supply_total   utxo_count  \n",
       "0      3.536407e+13  1.924871e+07   83308092.0  \n",
       "1      3.536407e+13  1.924874e+07   83314883.0  \n",
       "2      3.536407e+13  1.924879e+07   83314090.0  \n",
       "3      3.536407e+13  1.924882e+07   83326258.0  \n",
       "4      3.536407e+13  1.924886e+07   83339168.0  \n",
       "...             ...           ...          ...  \n",
       "11547  8.810419e+13           NaN  179820708.0  \n",
       "11548  8.810419e+13           NaN  179833897.0  \n",
       "11549  8.810419e+13           NaN  179851249.0  \n",
       "11550  8.810419e+13           NaN  179852452.0  \n",
       "11551  8.810419e+13           NaN          NaN  \n",
       "\n",
       "[11552 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _type에 따라 train, test 분리\n",
    "train_df = df.loc[df[\"_type\"]==\"train\"].drop(columns=[\"_type\"])\n",
    "test_df = df.loc[df[\"_type\"]==\"test\"].drop(columns=[\"_type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost 라이브러리에 구현되어 있는 XGBRegressor 모델을 사용하여 학습 및 평가를 진행합니다. xgboost의 래퍼 클래스(wrapper class) 중 **사이킷런 래퍼**를 사용할 예정입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model parameter (XGBRegressor)\n",
    "* n_estimator: 트리의 개수 (디폴트 = 100)  \n",
    "\n",
    "* learning_rate: 학습 단계별 가중치를 얼마나 사용할지(이전 결과를 얼마나 반영할 것인지) 결정. 일반적으로 0.01 ~ 0.2\n",
    "\n",
    "* max_depth: 트리의 최대 깊이. (디폴트 = 6) 일반적으로 3 ~ 10  \n",
    "\n",
    "* min_child_weight: child에서 필요한 모든 관측치에 대한 가중치의 최소 합. 이 값보다 샘플 수가 작으면 leaf node가 된다. 너무 큰 값을 적용하면 과소적합이 될 수 있다.  \n",
    "\n",
    "* early stopping_rounds: 최대한 몇 개의 트리를 완성해볼 것인지 결정. valid loss에 더 이상 진전이 없으면 멈춘다. n_estimator가 높을 때 주로 사용  \n",
    "\n",
    "* gamma: 트리에서 추가적으로 가지를 나눌지를 결정할 최소 손실 감소값. 값이 클수록 과적합 감소 효과  \n",
    "\n",
    "* subsample: 각 트리마다 데이터 샘플링 비율. (디폴트 = 1) 일반적으로 0.5 ~ 1  \n",
    "\n",
    "* colsample_bytree: 각 트리마다 feature 샘플링 비율. (디폴트 = 1) 일반적으로 0.5 ~ 1  \n",
    "\n",
    "* reg_lambda: L2 regularization 가중치 (디폴트 = 1)  \n",
    "\n",
    "* reg_alpha: L1 regularization 가중치 (디폴트 = 1)  \n",
    "\n",
    "* scale_pos_weight: 데이터가 불균형할때 사용, 0보다 큰 값. (디폴트 = 1) 보통 값을 (음성 데이터 수)/(양성 데이터 수) 값으로 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fit 파라미터\n",
    "\n",
    "* early_stopping_rounds:\n",
    "* eval_metric: \n",
    "* eval_set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop([\"ID\", \"target\", \"close\"], axis=1)\n",
    "y_train = train_df[\"close\"]\n",
    "target = train_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_to_class(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"close 변수를 target값으로 변환하는 함수입니다.\n",
    "\n",
    "    Args:\n",
    "        series (pd.Series): 변환을 원하는 close 변수\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: 변환된 target 값\n",
    "    \"\"\"\n",
    "    close = pd.DataFrame()\n",
    "    close['close'] = series\n",
    "    close['close_lag1'] = close['close'].shift(1)\n",
    "    close['close_lag1_percent'] = (close['close'] - close['close_lag1']) / close['close_lag1']\n",
    "    close['class'] = close['close']\n",
    "    for i in range(close.shape[0]):\n",
    "        if close.loc[i, 'close_lag1_percent'] < -0.005:\n",
    "            close.loc[i, 'class'] = 0\n",
    "        elif close.loc[i, 'close_lag1_percent'] < 0:\n",
    "            close.loc[i, 'class'] = 1\n",
    "        elif close.loc[i, 'close_lag1_percent'] < 0.005:\n",
    "            close.loc[i, 'class'] = 2\n",
    "        else:\n",
    "            close.loc[i, 'class'] = 3\n",
    "            \n",
    "    return close[\"class\"].shift(-1).fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "def evaluate(valid_target: pd.Series, \n",
    "             y_valid: pd.Series, \n",
    "             y_pred: np.ndarray, \n",
    "             metric: str\n",
    ") -> float:\n",
    "    \"\"\"평가지표 metric을 반환하는 함수입니다.\n",
    "\n",
    "    Args:\n",
    "        valid_target: (pd.Series): \n",
    "        y_valid (pd.Series): \n",
    "        y_pred (np.ndarray): 모델을 사용하여 예측한 변수\n",
    "        metric (str): 사용할 평가지표 metric 이름\n",
    "\n",
    "    Returns:\n",
    "        float: 사용할 평가지표 metric 값\n",
    "    \"\"\"\n",
    "    if metric == \"accuracy\":\n",
    "        classes = close_to_class(y_pred)\n",
    "        return accuracy_score(valid_target, classes)\n",
    "    elif metric == \"mae\":\n",
    "        return mean_absolute_error(y_valid, y_pred)\n",
    "    elif metric == \"mse\":\n",
    "        return mean_squared_error(y_valid, y_pred)\n",
    "    elif metric == \"mape\":\n",
    "        return mean_absolute_percentage_error(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model: Any, \n",
    "                X_train: pd.DataFrame, \n",
    "                y_train: pd.Series, \n",
    "                cv: int, \n",
    "                metric: str, \n",
    ") -> float:\n",
    "    \"\"\"K-Fold로 데이터를 분할한 후 전처리를 거쳐 주어진 모델로 데이터를 학습 및 평가를 진행합니다.\n",
    "\n",
    "    Args:\n",
    "        model (Any): 사용하는 모델 객체\n",
    "        X_train (pd.DataFrame): 설명변수로 이루어진 학습 데이터프레임\n",
    "        y_train (pd.Seris): 예측변수로 이루어진 학습 시리즈\n",
    "        cv (int): 교차검증시 분할할 폴드의 수\n",
    "        metric (str): 사용할 평가지표 metric 이름\n",
    "\n",
    "    Returns:\n",
    "        Any, float: \n",
    "    \"\"\"\n",
    "    kfold = KFold(n_splits=cv)\n",
    "    # kfold = KFold(n_splits=cv, shuffle=True, random_state=42)  # shuffle 켰을 때\n",
    "    score_list = []\n",
    "    \n",
    "    # warm_start는 모델의 속성으로, 같은 모델을 반복 학습할 때 이전 학습에서 학습된 파라미터를 초기화하지 않고 이어서 학습을 진행하는 옵션\n",
    "    if hasattr(model, \"warm_start\"):\n",
    "        model.warm_start = True\n",
    "\n",
    "    # K-Fold 교차 검증\n",
    "    for train_index, valid_index in kfold.split(X_train):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_valid, y_valid = X_train.iloc[valid_index], y_train.iloc[valid_index]\n",
    "\n",
    "        valid_target = target[valid_index]\n",
    "        \n",
    "        # 전처리\n",
    "        X_train_fold.fillna(X_train_fold.mean(), inplace=True)\n",
    "        y_train_fold.fillna(y_train_fold.mean(), inplace=True)\n",
    "        X_valid.fillna(X_valid.mean(), inplace=True)\n",
    "        y_valid.fillna(y_valid.mean(), inplace=True)  # 이 부분을 mice와 같은 방법으로 조정할 예정. feature selection 등도 여기에서.\n",
    "\n",
    "        \n",
    "        # 모델 학습\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        y_pred = model.predict(X_valid)\n",
    "        score = evaluate(valid_target, y_valid, y_pred, metric=metric)  # 평가지표 metric 반환\n",
    "        score_list.append(score)\n",
    "    \n",
    "    return np.mean(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1e-1),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 9),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 5),\n",
    "        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.3, 1.0),\n",
    "        \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
    "        \"device\": \"gpu\",\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "    \n",
    "    xgb_model = XGBRegressor(**params)\n",
    "    acc = model_train(xgb_model, X_train, y_train, cv=5, metric=\"accuracy\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-24 21:17:39,908] A new study created in memory with name: no-name-1a90c5b5-b90c-455c-8664-e56a944cc66b\n",
      "[I 2024-09-24 21:17:43,371] Trial 0 finished with value: 0.4265981735159817 and parameters: {'n_estimators': 250, 'learning_rate': 0.002200629863982853, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.5495564512723209, 'subsample': 0.7955436533174249}. Best is trial 0 with value: 0.4265981735159817.\n",
      "[I 2024-09-24 21:17:45,856] Trial 1 finished with value: 0.42271689497716897 and parameters: {'n_estimators': 103, 'learning_rate': 0.0014207344061369256, 'max_depth': 3, 'min_child_weight': 5, 'colsample_bytree': 0.6832856917627255, 'subsample': 0.9323033460453602}. Best is trial 0 with value: 0.4265981735159817.\n",
      "[I 2024-09-24 21:17:49,161] Trial 2 finished with value: 0.41689497716894974 and parameters: {'n_estimators': 159, 'learning_rate': 0.06633601878187961, 'max_depth': 7, 'min_child_weight': 5, 'colsample_bytree': 0.8381230142214211, 'subsample': 0.6063262393326437}. Best is trial 0 with value: 0.4265981735159817.\n",
      "[I 2024-09-24 21:17:53,692] Trial 3 finished with value: 0.4210045662100456 and parameters: {'n_estimators': 267, 'learning_rate': 0.003938485786369116, 'max_depth': 8, 'min_child_weight': 1, 'colsample_bytree': 0.9709244097874965, 'subsample': 0.8879037977561531}. Best is trial 0 with value: 0.4265981735159817.\n",
      "[I 2024-09-24 21:17:56,620] Trial 4 finished with value: 0.4125570776255708 and parameters: {'n_estimators': 76, 'learning_rate': 0.08304835711019291, 'max_depth': 9, 'min_child_weight': 4, 'colsample_bytree': 0.5429160609305692, 'subsample': 0.6448773334525706}. Best is trial 0 with value: 0.4265981735159817.\n",
      "[I 2024-09-24 21:17:59,754] Trial 5 finished with value: 0.4363013698630137 and parameters: {'n_estimators': 133, 'learning_rate': 0.0013185732918073658, 'max_depth': 8, 'min_child_weight': 4, 'colsample_bytree': 0.31088380708464286, 'subsample': 0.9189389153425427}. Best is trial 5 with value: 0.4363013698630137.\n",
      "[I 2024-09-24 21:18:02,573] Trial 6 finished with value: 0.4357305936073059 and parameters: {'n_estimators': 196, 'learning_rate': 0.027202654930341734, 'max_depth': 3, 'min_child_weight': 2, 'colsample_bytree': 0.5389244471176597, 'subsample': 0.6542235256987465}. Best is trial 5 with value: 0.4363013698630137.\n",
      "[I 2024-09-24 21:18:05,614] Trial 7 finished with value: 0.4374429223744293 and parameters: {'n_estimators': 127, 'learning_rate': 0.004198031379502821, 'max_depth': 8, 'min_child_weight': 3, 'colsample_bytree': 0.3847568446729976, 'subsample': 0.5819924967628434}. Best is trial 7 with value: 0.4374429223744293.\n",
      "[I 2024-09-24 21:18:08,517] Trial 8 finished with value: 0.41575342465753423 and parameters: {'n_estimators': 71, 'learning_rate': 0.05803236524456451, 'max_depth': 9, 'min_child_weight': 1, 'colsample_bytree': 0.6312615507662388, 'subsample': 0.9173046809446177}. Best is trial 7 with value: 0.4374429223744293.\n",
      "[I 2024-09-24 21:18:11,423] Trial 9 finished with value: 0.42522831050228305 and parameters: {'n_estimators': 194, 'learning_rate': 0.005356761865673611, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.5100007378400054, 'subsample': 0.923505088534491}. Best is trial 7 with value: 0.4374429223744293.\n",
      "[I 2024-09-24 21:18:14,775] Trial 10 finished with value: 0.43436073059360725 and parameters: {'n_estimators': 226, 'learning_rate': 0.010378360683447009, 'max_depth': 5, 'min_child_weight': 3, 'colsample_bytree': 0.3037412831524246, 'subsample': 0.5037618299626561}. Best is trial 7 with value: 0.4374429223744293.\n",
      "[I 2024-09-24 21:18:17,815] Trial 11 finished with value: 0.43778538812785384 and parameters: {'n_estimators': 135, 'learning_rate': 0.0011410828344069269, 'max_depth': 7, 'min_child_weight': 3, 'colsample_bytree': 0.3206436319426255, 'subsample': 0.7779104910046594}. Best is trial 11 with value: 0.43778538812785384.\n",
      "[I 2024-09-24 21:18:20,744] Trial 12 finished with value: 0.43378995433789963 and parameters: {'n_estimators': 130, 'learning_rate': 0.011278414190051045, 'max_depth': 6, 'min_child_weight': 3, 'colsample_bytree': 0.40646512864168743, 'subsample': 0.7637632416595601}. Best is trial 11 with value: 0.43778538812785384.\n",
      "[I 2024-09-24 21:18:23,917] Trial 13 finished with value: 0.4344748858447488 and parameters: {'n_estimators': 154, 'learning_rate': 0.0030060965799822382, 'max_depth': 7, 'min_child_weight': 3, 'colsample_bytree': 0.43346414839847536, 'subsample': 0.822381214779347}. Best is trial 11 with value: 0.43778538812785384.\n",
      "[I 2024-09-24 21:18:26,765] Trial 14 finished with value: 0.4367579908675799 and parameters: {'n_estimators': 107, 'learning_rate': 0.006325515847538973, 'max_depth': 7, 'min_child_weight': 2, 'colsample_bytree': 0.41520422228022275, 'subsample': 0.7046117158000652}. Best is trial 11 with value: 0.43778538812785384.\n",
      "[I 2024-09-24 21:18:29,206] Trial 15 finished with value: 0.4281963470319635 and parameters: {'n_estimators': 51, 'learning_rate': 0.0010537078437156452, 'max_depth': 6, 'min_child_weight': 2, 'colsample_bytree': 0.7060851785603328, 'subsample': 0.5701543768765025}. Best is trial 11 with value: 0.43778538812785384.\n",
      "[I 2024-09-24 21:18:32,920] Trial 16 finished with value: 0.4237442922374429 and parameters: {'n_estimators': 189, 'learning_rate': 0.020368966259038414, 'max_depth': 8, 'min_child_weight': 3, 'colsample_bytree': 0.3565768325124506, 'subsample': 0.5178390006053236}. Best is trial 11 with value: 0.43778538812785384.\n",
      "[I 2024-09-24 21:18:36,581] Trial 17 finished with value: 0.4397260273972603 and parameters: {'n_estimators': 292, 'learning_rate': 0.001972319027402576, 'max_depth': 5, 'min_child_weight': 4, 'colsample_bytree': 0.47325898142376704, 'subsample': 0.7258403981748291}. Best is trial 17 with value: 0.4397260273972603.\n",
      "[I 2024-09-24 21:18:40,261] Trial 18 finished with value: 0.43173515981735167 and parameters: {'n_estimators': 287, 'learning_rate': 0.002072358967409622, 'max_depth': 5, 'min_child_weight': 4, 'colsample_bytree': 0.4671756128264716, 'subsample': 0.9917201115364017}. Best is trial 17 with value: 0.4397260273972603.\n",
      "[I 2024-09-24 21:18:43,570] Trial 19 finished with value: 0.43230593607305934 and parameters: {'n_estimators': 217, 'learning_rate': 0.00203942941753551, 'max_depth': 5, 'min_child_weight': 5, 'colsample_bytree': 0.6107943973565294, 'subsample': 0.7145286471519897}. Best is trial 17 with value: 0.4397260273972603.\n",
      "[I 2024-09-24 21:18:46,769] Trial 20 finished with value: 0.4256849315068493 and parameters: {'n_estimators': 236, 'learning_rate': 0.0010554567762498092, 'max_depth': 4, 'min_child_weight': 4, 'colsample_bytree': 0.7564180605440388, 'subsample': 0.8430207121503202}. Best is trial 17 with value: 0.4397260273972603.\n",
      "[I 2024-09-24 21:18:49,617] Trial 21 finished with value: 0.4371004566210046 and parameters: {'n_estimators': 124, 'learning_rate': 0.0034715301884861135, 'max_depth': 6, 'min_child_weight': 2, 'colsample_bytree': 0.3514698659619593, 'subsample': 0.7093136140476773}. Best is trial 17 with value: 0.4397260273972603.\n",
      "[I 2024-09-24 21:18:53,837] Trial 22 finished with value: 0.43538812785388126 and parameters: {'n_estimators': 298, 'learning_rate': 0.004835284973530396, 'max_depth': 7, 'min_child_weight': 3, 'colsample_bytree': 0.37676864570595714, 'subsample': 0.7584203679505297}. Best is trial 17 with value: 0.4397260273972603.\n",
      "[I 2024-09-24 21:18:57,192] Trial 23 finished with value: 0.43755707762557083 and parameters: {'n_estimators': 161, 'learning_rate': 0.0025901339850415185, 'max_depth': 8, 'min_child_weight': 4, 'colsample_bytree': 0.46237084086631464, 'subsample': 0.6601303726168732}. Best is trial 17 with value: 0.4397260273972603.\n",
      "[I 2024-09-24 21:19:00,647] Trial 24 finished with value: 0.4385844748858448 and parameters: {'n_estimators': 161, 'learning_rate': 0.001968219118229883, 'max_depth': 9, 'min_child_weight': 4, 'colsample_bytree': 0.47486831437388477, 'subsample': 0.6445131018036367}. Best is trial 17 with value: 0.4397260273972603.\n",
      "[I 2024-09-24 21:19:04,405] Trial 25 finished with value: 0.4284246575342466 and parameters: {'n_estimators': 174, 'learning_rate': 0.0015011254316813322, 'max_depth': 9, 'min_child_weight': 5, 'colsample_bytree': 0.5917324528228005, 'subsample': 0.7322061803029922}. Best is trial 17 with value: 0.4397260273972603.\n",
      "[I 2024-09-24 21:19:07,164] Trial 26 finished with value: 0.4363013698630137 and parameters: {'n_estimators': 146, 'learning_rate': 0.006947423358540925, 'max_depth': 4, 'min_child_weight': 4, 'colsample_bytree': 0.48440387154179176, 'subsample': 0.6759181957798752}. Best is trial 17 with value: 0.4397260273972603.\n",
      "[I 2024-09-24 21:19:10,608] Trial 27 finished with value: 0.4261415525114155 and parameters: {'n_estimators': 206, 'learning_rate': 0.0017604846969632433, 'max_depth': 6, 'min_child_weight': 4, 'colsample_bytree': 0.7848797120183475, 'subsample': 0.7849739474913024}. Best is trial 17 with value: 0.4397260273972603.\n",
      "[I 2024-09-24 21:19:13,723] Trial 28 finished with value: 0.4301369863013699 and parameters: {'n_estimators': 178, 'learning_rate': 0.00252566618176571, 'max_depth': 5, 'min_child_weight': 5, 'colsample_bytree': 0.5806253318555955, 'subsample': 0.8452905076632322}. Best is trial 17 with value: 0.4397260273972603.\n",
      "[I 2024-09-24 21:19:18,281] Trial 29 finished with value: 0.4308219178082192 and parameters: {'n_estimators': 257, 'learning_rate': 0.0010669057930826503, 'max_depth': 9, 'min_child_weight': 4, 'colsample_bytree': 0.5044338169590845, 'subsample': 0.8035579758132214}. Best is trial 17 with value: 0.4397260273972603.\n",
      "[I 2024-09-24 21:19:20,815] Trial 30 finished with value: 0.4374429223744293 and parameters: {'n_estimators': 98, 'learning_rate': 0.018651742372905088, 'max_depth': 4, 'min_child_weight': 3, 'colsample_bytree': 0.4359565139256884, 'subsample': 0.6128098815387597}. Best is trial 17 with value: 0.4397260273972603.\n",
      "[I 2024-09-24 21:19:24,242] Trial 31 finished with value: 0.43744292237442917 and parameters: {'n_estimators': 172, 'learning_rate': 0.0025048800132280846, 'max_depth': 8, 'min_child_weight': 4, 'colsample_bytree': 0.45890188529692194, 'subsample': 0.6804604664172073}. Best is trial 17 with value: 0.4397260273972603.\n",
      "[I 2024-09-24 21:19:27,407] Trial 32 finished with value: 0.4280821917808219 and parameters: {'n_estimators': 144, 'learning_rate': 0.0016934543558171217, 'max_depth': 7, 'min_child_weight': 5, 'colsample_bytree': 0.5446180258608398, 'subsample': 0.6421257154109091}. Best is trial 17 with value: 0.4397260273972603.\n",
      "[I 2024-09-24 21:19:30,795] Trial 33 finished with value: 0.4367579908675799 and parameters: {'n_estimators': 165, 'learning_rate': 0.0029600564070928555, 'max_depth': 8, 'min_child_weight': 4, 'colsample_bytree': 0.34253286171849634, 'subsample': 0.7422666055967558}. Best is trial 17 with value: 0.4397260273972603.\n",
      "[I 2024-09-24 21:19:33,886] Trial 34 finished with value: 0.42979452054794526 and parameters: {'n_estimators': 106, 'learning_rate': 0.0014531478032416675, 'max_depth': 9, 'min_child_weight': 3, 'colsample_bytree': 0.6539504720361885, 'subsample': 0.6108013650942323}. Best is trial 17 with value: 0.4397260273972603.\n",
      "[I 2024-09-24 21:19:37,294] Trial 35 finished with value: 0.43242009132420095 and parameters: {'n_estimators': 156, 'learning_rate': 0.002159553459466604, 'max_depth': 8, 'min_child_weight': 4, 'colsample_bytree': 0.897046112310733, 'subsample': 0.5485412875491698}. Best is trial 17 with value: 0.4397260273972603.\n",
      "[I 2024-09-24 21:19:41,309] Trial 36 finished with value: 0.43961187214611874 and parameters: {'n_estimators': 276, 'learning_rate': 0.0012592682124532152, 'max_depth': 7, 'min_child_weight': 5, 'colsample_bytree': 0.49847834966570753, 'subsample': 0.680680767986227}. Best is trial 17 with value: 0.4397260273972603.\n",
      "[I 2024-09-24 21:19:45,502] Trial 37 finished with value: 0.4333333333333334 and parameters: {'n_estimators': 281, 'learning_rate': 0.0012563105731864558, 'max_depth': 7, 'min_child_weight': 5, 'colsample_bytree': 0.5641141803939961, 'subsample': 0.7794116745862051}. Best is trial 17 with value: 0.4397260273972603.\n",
      "[I 2024-09-24 21:19:48,950] Trial 38 finished with value: 0.431392694063927 and parameters: {'n_estimators': 243, 'learning_rate': 0.001755730951938761, 'max_depth': 5, 'min_child_weight': 5, 'colsample_bytree': 0.5257763266847655, 'subsample': 0.6897700991260056}. Best is trial 17 with value: 0.4397260273972603.\n",
      "[I 2024-09-24 21:19:52,777] Trial 39 finished with value: 0.4264840182648403 and parameters: {'n_estimators': 270, 'learning_rate': 0.0013907892795061113, 'max_depth': 6, 'min_child_weight': 5, 'colsample_bytree': 0.6742692504199062, 'subsample': 0.8737870591000563}. Best is trial 17 with value: 0.4397260273972603.\n",
      "[I 2024-09-24 21:19:56,761] Trial 40 finished with value: 0.41963470319634705 and parameters: {'n_estimators': 263, 'learning_rate': 0.040288234377245116, 'max_depth': 7, 'min_child_weight': 5, 'colsample_bytree': 0.326196301442839, 'subsample': 0.6424819723921839}. Best is trial 17 with value: 0.4397260273972603.\n",
      "[I 2024-09-24 21:20:01,290] Trial 41 finished with value: 0.44189497716894977 and parameters: {'n_estimators': 300, 'learning_rate': 0.00317066253478483, 'max_depth': 8, 'min_child_weight': 4, 'colsample_bytree': 0.4550185797897145, 'subsample': 0.6587006604787923}. Best is trial 41 with value: 0.44189497716894977.\n",
      "[I 2024-09-24 21:20:06,098] Trial 42 finished with value: 0.4405251141552512 and parameters: {'n_estimators': 300, 'learning_rate': 0.0032077052116396597, 'max_depth': 9, 'min_child_weight': 4, 'colsample_bytree': 0.394698919842429, 'subsample': 0.6277367385131214}. Best is trial 41 with value: 0.44189497716894977.\n",
      "[I 2024-09-24 21:20:10,849] Trial 43 finished with value: 0.44075342465753425 and parameters: {'n_estimators': 297, 'learning_rate': 0.003908482101636308, 'max_depth': 9, 'min_child_weight': 4, 'colsample_bytree': 0.39318091875230765, 'subsample': 0.6202581835023468}. Best is trial 41 with value: 0.44189497716894977.\n",
      "[I 2024-09-24 21:20:15,619] Trial 44 finished with value: 0.4389269406392694 and parameters: {'n_estimators': 300, 'learning_rate': 0.0038364808964690225, 'max_depth': 9, 'min_child_weight': 4, 'colsample_bytree': 0.3884627322416953, 'subsample': 0.578584389317816}. Best is trial 41 with value: 0.44189497716894977.\n",
      "[I 2024-09-24 21:20:20,222] Trial 45 finished with value: 0.43493150684931503 and parameters: {'n_estimators': 278, 'learning_rate': 0.007025002141083363, 'max_depth': 9, 'min_child_weight': 4, 'colsample_bytree': 0.42489072740158157, 'subsample': 0.6186487897309968}. Best is trial 41 with value: 0.44189497716894977.\n",
      "[I 2024-09-24 21:20:24,877] Trial 46 finished with value: 0.43310502283105023 and parameters: {'n_estimators': 290, 'learning_rate': 0.004987403217779919, 'max_depth': 8, 'min_child_weight': 5, 'colsample_bytree': 0.9987994527577945, 'subsample': 0.6269474681353576}. Best is trial 41 with value: 0.44189497716894977.\n",
      "[I 2024-09-24 21:20:29,382] Trial 47 finished with value: 0.4372146118721461 and parameters: {'n_estimators': 253, 'learning_rate': 0.0032851293654415194, 'max_depth': 9, 'min_child_weight': 4, 'colsample_bytree': 0.5031586717894203, 'subsample': 0.5869070113764294}. Best is trial 41 with value: 0.44189497716894977.\n",
      "[I 2024-09-24 21:20:33,695] Trial 48 finished with value: 0.4275114155251142 and parameters: {'n_estimators': 273, 'learning_rate': 0.008715121095977042, 'max_depth': 8, 'min_child_weight': 5, 'colsample_bytree': 0.38743590117952786, 'subsample': 0.5376216695707502}. Best is trial 41 with value: 0.44189497716894977.\n",
      "[I 2024-09-24 21:20:38,082] Trial 49 finished with value: 0.44223744292237444 and parameters: {'n_estimators': 288, 'learning_rate': 0.0038303464529163027, 'max_depth': 8, 'min_child_weight': 1, 'colsample_bytree': 0.44219555657895193, 'subsample': 0.6687509470531152}. Best is trial 49 with value: 0.44223744292237444.\n",
      "[I 2024-09-24 21:20:42,751] Trial 50 finished with value: 0.43801369863013695 and parameters: {'n_estimators': 288, 'learning_rate': 0.004126514589012136, 'max_depth': 9, 'min_child_weight': 1, 'colsample_bytree': 0.4365094415155469, 'subsample': 0.5949376945225164}. Best is trial 49 with value: 0.44223744292237444.\n",
      "[I 2024-09-24 21:20:47,208] Trial 51 finished with value: 0.4415525114155251 and parameters: {'n_estimators': 299, 'learning_rate': 0.0028882653213457986, 'max_depth': 8, 'min_child_weight': 1, 'colsample_bytree': 0.40911229519239295, 'subsample': 0.6734411297985726}. Best is trial 49 with value: 0.44223744292237444.\n",
      "[I 2024-09-24 21:20:51,683] Trial 52 finished with value: 0.4367579908675799 and parameters: {'n_estimators': 295, 'learning_rate': 0.0059414917969060465, 'max_depth': 8, 'min_child_weight': 1, 'colsample_bytree': 0.4085412906821684, 'subsample': 0.665662172110409}. Best is trial 49 with value: 0.44223744292237444.\n",
      "[I 2024-09-24 21:20:55,883] Trial 53 finished with value: 0.43995433789954336 and parameters: {'n_estimators': 265, 'learning_rate': 0.0029906446297389743, 'max_depth': 8, 'min_child_weight': 1, 'colsample_bytree': 0.37590995684557466, 'subsample': 0.7287773821181021}. Best is trial 49 with value: 0.44223744292237444.\n",
      "[I 2024-09-24 21:21:00,161] Trial 54 finished with value: 0.43961187214611874 and parameters: {'n_estimators': 261, 'learning_rate': 0.004553797847983508, 'max_depth': 8, 'min_child_weight': 1, 'colsample_bytree': 0.3034625212478031, 'subsample': 0.6913108408332254}. Best is trial 49 with value: 0.44223744292237444.\n",
      "[I 2024-09-24 21:21:04,513] Trial 55 finished with value: 0.43630136986301365 and parameters: {'n_estimators': 284, 'learning_rate': 0.0029707151882242063, 'max_depth': 8, 'min_child_weight': 1, 'colsample_bytree': 0.3714470331580084, 'subsample': 0.5623376545428044}. Best is trial 49 with value: 0.44223744292237444.\n",
      "[I 2024-09-24 21:21:09,279] Trial 56 finished with value: 0.4420091324200913 and parameters: {'n_estimators': 300, 'learning_rate': 0.0036771618366702795, 'max_depth': 9, 'min_child_weight': 1, 'colsample_bytree': 0.349866134159473, 'subsample': 0.6269535057905342}. Best is trial 49 with value: 0.44223744292237444.\n",
      "[I 2024-09-24 21:21:14,192] Trial 57 finished with value: 0.42796803652968035 and parameters: {'n_estimators': 300, 'learning_rate': 0.008639514330188077, 'max_depth': 9, 'min_child_weight': 2, 'colsample_bytree': 0.3462017901011054, 'subsample': 0.6250434115901976}. Best is trial 49 with value: 0.44223744292237444.\n",
      "[I 2024-09-24 21:21:18,566] Trial 58 finished with value: 0.42340182648401825 and parameters: {'n_estimators': 241, 'learning_rate': 0.013899226369303807, 'max_depth': 9, 'min_child_weight': 1, 'colsample_bytree': 0.39670295562542424, 'subsample': 0.6365448534751393}. Best is trial 49 with value: 0.44223744292237444.\n",
      "[I 2024-09-24 21:21:23,205] Trial 59 finished with value: 0.43424657534246575 and parameters: {'n_estimators': 283, 'learning_rate': 0.005446245179868777, 'max_depth': 9, 'min_child_weight': 2, 'colsample_bytree': 0.3229001231699503, 'subsample': 0.5951641281855213}. Best is trial 49 with value: 0.44223744292237444.\n",
      "[I 2024-09-24 21:21:27,524] Trial 60 finished with value: 0.43824200913242006 and parameters: {'n_estimators': 248, 'learning_rate': 0.0035077421732114915, 'max_depth': 9, 'min_child_weight': 1, 'colsample_bytree': 0.4423714302569265, 'subsample': 0.660863857770695}. Best is trial 49 with value: 0.44223744292237444.\n",
      "[I 2024-09-24 21:21:31,808] Trial 61 finished with value: 0.43938356164383563 and parameters: {'n_estimators': 270, 'learning_rate': 0.0038697062326503245, 'max_depth': 8, 'min_child_weight': 1, 'colsample_bytree': 0.36430026169619906, 'subsample': 0.6985247487186802}. Best is trial 49 with value: 0.44223744292237444.\n",
      "[I 2024-09-24 21:21:36,246] Trial 62 finished with value: 0.44257990867579905 and parameters: {'n_estimators': 292, 'learning_rate': 0.002528754832095206, 'max_depth': 8, 'min_child_weight': 1, 'colsample_bytree': 0.4055086523795775, 'subsample': 0.7148015710742931}. Best is trial 62 with value: 0.44257990867579905.\n",
      "[I 2024-09-24 21:21:40,846] Trial 63 finished with value: 0.4405251141552512 and parameters: {'n_estimators': 292, 'learning_rate': 0.0024434082513801582, 'max_depth': 8, 'min_child_weight': 1, 'colsample_bytree': 0.4014439174980016, 'subsample': 0.7123065256339007}. Best is trial 62 with value: 0.44257990867579905.\n",
      "[I 2024-09-24 21:21:45,651] Trial 64 finished with value: 0.44063926940639264 and parameters: {'n_estimators': 300, 'learning_rate': 0.004362381806033782, 'max_depth': 9, 'min_child_weight': 2, 'colsample_bytree': 0.4498498532859675, 'subsample': 0.6561915760507339}. Best is trial 62 with value: 0.44257990867579905.\n",
      "[I 2024-09-24 21:21:50,135] Trial 65 finished with value: 0.44223744292237444 and parameters: {'n_estimators': 285, 'learning_rate': 0.004423002853264547, 'max_depth': 8, 'min_child_weight': 2, 'colsample_bytree': 0.419921557290779, 'subsample': 0.6559352938396962}. Best is trial 62 with value: 0.44257990867579905.\n",
      "[I 2024-09-24 21:21:54,536] Trial 66 finished with value: 0.4147260273972603 and parameters: {'n_estimators': 282, 'learning_rate': 0.09504535465268668, 'max_depth': 8, 'min_child_weight': 2, 'colsample_bytree': 0.4187546771430661, 'subsample': 0.670340438939361}. Best is trial 62 with value: 0.44257990867579905.\n",
      "[I 2024-09-24 21:21:58,667] Trial 67 finished with value: 0.44143835616438354 and parameters: {'n_estimators': 289, 'learning_rate': 0.0026498908552723575, 'max_depth': 7, 'min_child_weight': 1, 'colsample_bytree': 0.33894793956615726, 'subsample': 0.7460574585247228}. Best is trial 62 with value: 0.44257990867579905.\n",
      "[I 2024-09-24 21:22:02,864] Trial 68 finished with value: 0.44326484018264845 and parameters: {'n_estimators': 276, 'learning_rate': 0.002641942245669079, 'max_depth': 7, 'min_child_weight': 1, 'colsample_bytree': 0.33957888269110675, 'subsample': 0.7426869369733715}. Best is trial 68 with value: 0.44326484018264845.\n",
      "[I 2024-09-24 21:22:06,922] Trial 69 finished with value: 0.44200913242009127 and parameters: {'n_estimators': 275, 'learning_rate': 0.002398434049876078, 'max_depth': 7, 'min_child_weight': 1, 'colsample_bytree': 0.4790517816907194, 'subsample': 0.7243639143621203}. Best is trial 68 with value: 0.44326484018264845.\n",
      "[I 2024-09-24 21:22:10,701] Trial 70 finished with value: 0.4405251141552512 and parameters: {'n_estimators': 229, 'learning_rate': 0.002249232555202138, 'max_depth': 7, 'min_child_weight': 1, 'colsample_bytree': 0.4834604361312433, 'subsample': 0.756100220835313}. Best is trial 68 with value: 0.44326484018264845.\n",
      "[I 2024-09-24 21:22:14,773] Trial 71 finished with value: 0.442351598173516 and parameters: {'n_estimators': 270, 'learning_rate': 0.0027575120218610847, 'max_depth': 7, 'min_child_weight': 1, 'colsample_bytree': 0.3567920460106891, 'subsample': 0.7315844363856365}. Best is trial 68 with value: 0.44326484018264845.\n",
      "[I 2024-09-24 21:22:18,821] Trial 72 finished with value: 0.44178082191780826 and parameters: {'n_estimators': 273, 'learning_rate': 0.002208924122329318, 'max_depth': 7, 'min_child_weight': 1, 'colsample_bytree': 0.30109936919541785, 'subsample': 0.7192421097916079}. Best is trial 68 with value: 0.44326484018264845.\n",
      "[I 2024-09-24 21:22:22,894] Trial 73 finished with value: 0.4392694063926941 and parameters: {'n_estimators': 278, 'learning_rate': 0.00354946279732229, 'max_depth': 7, 'min_child_weight': 1, 'colsample_bytree': 0.3618172866340358, 'subsample': 0.6950280431225058}. Best is trial 68 with value: 0.44326484018264845.\n",
      "[I 2024-09-24 21:22:26,591] Trial 74 finished with value: 0.4360730593607306 and parameters: {'n_estimators': 257, 'learning_rate': 0.0016952399250001824, 'max_depth': 6, 'min_child_weight': 2, 'colsample_bytree': 0.3347591414051539, 'subsample': 0.7694459670367704}. Best is trial 68 with value: 0.44326484018264845.\n",
      "[I 2024-09-24 21:22:30,812] Trial 75 finished with value: 0.4307077625570776 and parameters: {'n_estimators': 268, 'learning_rate': 0.002706377070679667, 'max_depth': 7, 'min_child_weight': 1, 'colsample_bytree': 0.5295187298010656, 'subsample': 0.8012717244700673}. Best is trial 68 with value: 0.44326484018264845.\n",
      "[I 2024-09-24 21:22:34,897] Trial 76 finished with value: 0.4377853881278539 and parameters: {'n_estimators': 288, 'learning_rate': 0.004985792169210993, 'max_depth': 6, 'min_child_weight': 1, 'colsample_bytree': 0.45678319940853357, 'subsample': 0.7102244261626215}. Best is trial 68 with value: 0.44326484018264845.\n",
      "[I 2024-09-24 21:22:38,870] Trial 77 finished with value: 0.43995433789954336 and parameters: {'n_estimators': 248, 'learning_rate': 0.0018902962340056123, 'max_depth': 7, 'min_child_weight': 2, 'colsample_bytree': 0.3601792614814032, 'subsample': 0.7386933554233986}. Best is trial 68 with value: 0.44326484018264845.\n",
      "[I 2024-09-24 21:22:42,953] Trial 78 finished with value: 0.434703196347032 and parameters: {'n_estimators': 277, 'learning_rate': 0.006631472290595845, 'max_depth': 7, 'min_child_weight': 1, 'colsample_bytree': 0.42977301461518846, 'subsample': 0.7311159764502143}. Best is trial 68 with value: 0.44326484018264845.\n",
      "[I 2024-09-24 21:22:47,029] Trial 79 finished with value: 0.4307077625570776 and parameters: {'n_estimators': 215, 'learning_rate': 0.0022365697341158977, 'max_depth': 8, 'min_child_weight': 2, 'colsample_bytree': 0.730582066648007, 'subsample': 0.8211997882637272}. Best is trial 68 with value: 0.44326484018264845.\n",
      "[I 2024-09-24 21:22:51,093] Trial 80 finished with value: 0.4341324200913242 and parameters: {'n_estimators': 259, 'learning_rate': 0.005714336877903091, 'max_depth': 7, 'min_child_weight': 1, 'colsample_bytree': 0.47712486780135965, 'subsample': 0.9647822426333117}. Best is trial 68 with value: 0.44326484018264845.\n",
      "[I 2024-09-24 21:22:55,137] Trial 81 finished with value: 0.44452054794520546 and parameters: {'n_estimators': 272, 'learning_rate': 0.0023345954714314885, 'max_depth': 7, 'min_child_weight': 1, 'colsample_bytree': 0.3103070586219113, 'subsample': 0.7152123371514675}. Best is trial 81 with value: 0.44452054794520546.\n",
      "[I 2024-09-24 21:22:59,352] Trial 82 finished with value: 0.43995433789954336 and parameters: {'n_estimators': 291, 'learning_rate': 0.0033387681320555004, 'max_depth': 7, 'min_child_weight': 1, 'colsample_bytree': 0.3264217923078886, 'subsample': 0.6862395204925996}. Best is trial 81 with value: 0.44452054794520546.\n",
      "[I 2024-09-24 21:23:03,620] Trial 83 finished with value: 0.4405251141552512 and parameters: {'n_estimators': 266, 'learning_rate': 0.0026332062490963177, 'max_depth': 8, 'min_child_weight': 1, 'colsample_bytree': 0.347436101359579, 'subsample': 0.767155741857298}. Best is trial 81 with value: 0.44452054794520546.\n",
      "[I 2024-09-24 21:23:07,593] Trial 84 finished with value: 0.4449771689497717 and parameters: {'n_estimators': 285, 'learning_rate': 0.0024171439975190358, 'max_depth': 6, 'min_child_weight': 1, 'colsample_bytree': 0.31834256836624825, 'subsample': 0.702400056995305}. Best is trial 84 with value: 0.4449771689497717.\n",
      "[I 2024-09-24 21:23:11,547] Trial 85 finished with value: 0.43812785388127856 and parameters: {'n_estimators': 281, 'learning_rate': 0.001587173769909771, 'max_depth': 6, 'min_child_weight': 1, 'colsample_bytree': 0.31029341345356143, 'subsample': 0.7494610817167111}. Best is trial 84 with value: 0.4449771689497717.\n",
      "[I 2024-09-24 21:23:15,245] Trial 86 finished with value: 0.4389269406392694 and parameters: {'n_estimators': 253, 'learning_rate': 0.0020068711452725114, 'max_depth': 6, 'min_child_weight': 1, 'colsample_bytree': 0.3170713412268051, 'subsample': 0.7190030200689991}. Best is trial 84 with value: 0.4449771689497717.\n",
      "[I 2024-09-24 21:23:19,035] Trial 87 finished with value: 0.4441780821917808 and parameters: {'n_estimators': 272, 'learning_rate': 0.002363276734902218, 'max_depth': 6, 'min_child_weight': 1, 'colsample_bytree': 0.3675145199699845, 'subsample': 0.703740607197725}. Best is trial 84 with value: 0.4449771689497717.\n",
      "[I 2024-09-24 21:23:22,717] Trial 88 finished with value: 0.4420091324200913 and parameters: {'n_estimators': 232, 'learning_rate': 0.003709463823528344, 'max_depth': 6, 'min_child_weight': 1, 'colsample_bytree': 0.38033124005955476, 'subsample': 0.6984502154733238}. Best is trial 84 with value: 0.4449771689497717.\n",
      "[I 2024-09-24 21:23:26,284] Trial 89 finished with value: 0.44223744292237444 and parameters: {'n_estimators': 270, 'learning_rate': 0.0028733378354120535, 'max_depth': 5, 'min_child_weight': 1, 'colsample_bytree': 0.3485403546780444, 'subsample': 0.7034746780600218}. Best is trial 84 with value: 0.4449771689497717.\n",
      "[I 2024-09-24 21:23:29,919] Trial 90 finished with value: 0.42728310502283107 and parameters: {'n_estimators': 264, 'learning_rate': 0.0018987017981316728, 'max_depth': 5, 'min_child_weight': 1, 'colsample_bytree': 0.851861089182247, 'subsample': 0.7904973299719017}. Best is trial 84 with value: 0.4449771689497717.\n",
      "[I 2024-09-24 21:23:33,581] Trial 91 finished with value: 0.44212328767123293 and parameters: {'n_estimators': 285, 'learning_rate': 0.0027741614154932954, 'max_depth': 5, 'min_child_weight': 1, 'colsample_bytree': 0.3559258624230746, 'subsample': 0.7071426375879583}. Best is trial 84 with value: 0.4449771689497717.\n",
      "[I 2024-09-24 21:23:37,199] Trial 92 finished with value: 0.4430365296803653 and parameters: {'n_estimators': 284, 'learning_rate': 0.002764684974269611, 'max_depth': 5, 'min_child_weight': 1, 'colsample_bytree': 0.33269015758623083, 'subsample': 0.7043789231918017}. Best is trial 84 with value: 0.4449771689497717.\n",
      "[I 2024-09-24 21:23:40,597] Trial 93 finished with value: 0.4377853881278539 and parameters: {'n_estimators': 275, 'learning_rate': 0.0023640688653325777, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.33786216381341855, 'subsample': 0.7428248996026027}. Best is trial 84 with value: 0.4449771689497717.\n",
      "[I 2024-09-24 21:23:44,256] Trial 94 finished with value: 0.4420091324200913 and parameters: {'n_estimators': 269, 'learning_rate': 0.003157762676273775, 'max_depth': 5, 'min_child_weight': 1, 'colsample_bytree': 0.31612557889757514, 'subsample': 0.6819405224049806}. Best is trial 84 with value: 0.4449771689497717.\n",
      "[I 2024-09-24 21:23:47,439] Trial 95 finished with value: 0.42591324200913244 and parameters: {'n_estimators': 256, 'learning_rate': 0.0015669325513331862, 'max_depth': 3, 'min_child_weight': 1, 'colsample_bytree': 0.3822088446223346, 'subsample': 0.7020887389572386}. Best is trial 84 with value: 0.4449771689497717.\n",
      "[I 2024-09-24 21:23:51,311] Trial 96 finished with value: 0.4415525114155251 and parameters: {'n_estimators': 285, 'learning_rate': 0.00437741403833743, 'max_depth': 6, 'min_child_weight': 1, 'colsample_bytree': 0.36877350321727626, 'subsample': 0.7582294708929639}. Best is trial 84 with value: 0.4449771689497717.\n",
      "[I 2024-09-24 21:23:54,948] Trial 97 finished with value: 0.4401826484018265 and parameters: {'n_estimators': 291, 'learning_rate': 0.0018612285834654504, 'max_depth': 5, 'min_child_weight': 1, 'colsample_bytree': 0.32600841534023517, 'subsample': 0.6516734292551148}. Best is trial 84 with value: 0.4449771689497717.\n",
      "[I 2024-09-24 21:23:58,464] Trial 98 finished with value: 0.43687214611872144 and parameters: {'n_estimators': 293, 'learning_rate': 0.002131321500213716, 'max_depth': 4, 'min_child_weight': 2, 'colsample_bytree': 0.40949738153709137, 'subsample': 0.7317923554423473}. Best is trial 84 with value: 0.4449771689497717.\n",
      "[I 2024-09-24 21:24:01,972] Trial 99 finished with value: 0.4426940639269407 and parameters: {'n_estimators': 242, 'learning_rate': 0.0028518623125821244, 'max_depth': 5, 'min_child_weight': 1, 'colsample_bytree': 0.32891205732762635, 'subsample': 0.6738493393630745}. Best is trial 84 with value: 0.4449771689497717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'n_estimators': 285, 'learning_rate': 0.0024171439975190358, 'max_depth': 6, 'min_child_weight': 1, 'colsample_bytree': 0.31834256836624825, 'subsample': 0.702400056995305}\n",
      "XGBoost model accuracy: 0.4449771689497717\n"
     ]
    }
   ],
   "source": [
    "# Optuna study 생성 및 최적화 실행\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"Best Hyperparameters: \", study.best_params)\n",
    "\n",
    "# 최적의 하이퍼파라미터를 사용하여 최종 모델 생성\n",
    "best_params = study.best_params\n",
    "best_params[\"device\"] = \"gpu\"\n",
    "best_params[\"random_state\"] = 42\n",
    "best_xgb_model = XGBRegressor(**best_params)\n",
    "\n",
    "# 최종 모델 평가\n",
    "acc = model_train(best_xgb_model, X_train, y_train, cv=5, metric=\"accuracy\")\n",
    "print(f\"XGBoost model accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop([\"ID\", \"target\", \"close\"], axis=1)\n",
    "X_test.fillna(X_test.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_xgb_model.predict(X_test)\n",
    "y_test_pred_class = close_to_class(y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output File Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output file 할당후 save \n",
    "submission_df = submission_df.assign(target = y_test_pred_class)\n",
    "submission_df[\"target\"] = submission_df[\"target\"].astype(np.int8)\n",
    "submission_df.to_csv(\"output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pd.read_csv(\"output.csv\")\n",
    "out[\"target\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion of 2: 0.9760028653295129\n",
      "# of 2: 2725\n",
      "proportion of 2: 0.023997134670487107\n",
      "# of 1: 67\n"
     ]
    }
   ],
   "source": [
    "prop2 = (out[\"target\"] == 2).mean()\n",
    "count2 = (out[\"target\"] == 2).sum()\n",
    "prop1 = (out[\"target\"] == 1).mean()\n",
    "count1 = (out[\"target\"] == 1).sum()\n",
    "\n",
    "print(f\"proportion of 2: {prop2}\")\n",
    "print(f\"# of 2: {count2}\")\n",
    "print(f\"proportion of 2: {prop1}\")\n",
    "print(f\"# of 1: {count1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-lecture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
