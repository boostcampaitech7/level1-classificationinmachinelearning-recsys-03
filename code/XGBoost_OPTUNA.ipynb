{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:15: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Any, List, Dict, Tuple\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "from data_preprocessing import *\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 호출\n",
    "data_path: str = \"/data/ephemeral/home/BTC/data\"\n",
    "train_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"train.csv\")).assign(_type=\"train\") # train 에는 _type = train \n",
    "test_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"test.csv\")).assign(_type=\"test\") # test 에는 _type = test\n",
    "submission_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"test.csv\")) # ID, target 열만 가진 데이터 미리 호출\n",
    "df: pd.DataFrame = pd.concat([train_df, test_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:03<00:00, 31.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# HOURLY_ 로 시작하는 .csv 파일 이름을 file_names 에 할딩\n",
    "file_names: List[str] = [\n",
    "    f for f in os.listdir(data_path) if f.startswith(\"HOURLY_\") and f.endswith(\".csv\")\n",
    "]\n",
    "\n",
    "# 파일명 : 데이터프레임으로 딕셔너리 형태로 저장\n",
    "file_dict: Dict[str, pd.DataFrame] = {\n",
    "    f.replace(\".csv\", \"\"): pd.read_csv(os.path.join(data_path, f)) for f in file_names\n",
    "}\n",
    "\n",
    "for _file_name, _df in tqdm(file_dict.items()):\n",
    "    # 열 이름 중복 방지를 위해 {_file_name.lower()}_{col.lower()}로 변경, datetime 열을 ID로 변경\n",
    "    _rename_rule = {\n",
    "        col: f\"{_file_name.lower()}_{col.lower()}\" if col != \"datetime\" else \"ID\"\n",
    "        for col in _df.columns\n",
    "    }\n",
    "    _df = _df.rename(_rename_rule, axis=1)\n",
    "    df = df.merge(_df, on=\"ID\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA (Explanatory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11552, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델에 사용할 컬럼, 컬럼의 rename rule을 미리 할당함\n",
    "cols_dict: Dict[str, str] = {\n",
    "    \"ID\": \"ID\",\n",
    "    \"target\": \"target\",\n",
    "    \"_type\" : \"_type\",\n",
    "    \"hourly_market-data_open-interest_all_exchange_all_symbol_open_interest\": \"open_interest\",\n",
    "    \"hourly_market-data_price-ohlcv_all_exchange_spot_btc_usd_close\": \"close\",\n",
    "    \"hourly_network-data_difficulty_difficulty\": \"difficulty\",\n",
    "    \"hourly_network-data_supply_supply_total\": \"supply_total\",\n",
    "    \"hourly_network-data_utxo-count_utxo_count\": \"utxo_count\"\n",
    "}\n",
    "df = df[cols_dict.keys()].rename(cols_dict, axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continuous 열을 따로 할당해둠\n",
    "conti_cols: List[str] = [\n",
    "    \"close\",\n",
    "    \"open_interest\",\n",
    "    \"difficulty\",\n",
    "    \"supply_total\",\n",
    "    \"utxo_count\"\n",
    "]\n",
    "\n",
    "# # 최대 24시간의 shift 피쳐를 계산\n",
    "# shift_list = shift_feature(\n",
    "#     df=df, conti_cols=conti_cols, intervals=[_ for _ in range(1, 24)]\n",
    "# )\n",
    "\n",
    "# # concat 하여 df 에 할당\n",
    "# df = pd.concat([df, pd.concat(shift_list, axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>_type</th>\n",
       "      <th>open_interest</th>\n",
       "      <th>close</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>supply_total</th>\n",
       "      <th>utxo_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6.271344e+09</td>\n",
       "      <td>16536.747967</td>\n",
       "      <td>3.536407e+13</td>\n",
       "      <td>1.924871e+07</td>\n",
       "      <td>83308092.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6.288683e+09</td>\n",
       "      <td>16557.136536</td>\n",
       "      <td>3.536407e+13</td>\n",
       "      <td>1.924874e+07</td>\n",
       "      <td>83314883.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 02:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6.286796e+09</td>\n",
       "      <td>16548.149805</td>\n",
       "      <td>3.536407e+13</td>\n",
       "      <td>1.924879e+07</td>\n",
       "      <td>83314090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 03:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6.284575e+09</td>\n",
       "      <td>16533.632875</td>\n",
       "      <td>3.536407e+13</td>\n",
       "      <td>1.924882e+07</td>\n",
       "      <td>83326258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 04:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6.291582e+09</td>\n",
       "      <td>16524.712159</td>\n",
       "      <td>3.536407e+13</td>\n",
       "      <td>1.924886e+07</td>\n",
       "      <td>83339168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11547</th>\n",
       "      <td>2024-04-26 03:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>1.486836e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.810419e+13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>179820708.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11548</th>\n",
       "      <td>2024-04-26 04:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.810419e+13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>179833897.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11549</th>\n",
       "      <td>2024-04-26 05:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.810419e+13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>179851249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11550</th>\n",
       "      <td>2024-04-26 06:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.810419e+13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>179852452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11551</th>\n",
       "      <td>2024-04-26 07:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.810419e+13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11552 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID  target  _type  open_interest         close  \\\n",
       "0      2023-01-01 00:00:00     2.0  train   6.271344e+09  16536.747967   \n",
       "1      2023-01-01 01:00:00     1.0  train   6.288683e+09  16557.136536   \n",
       "2      2023-01-01 02:00:00     1.0  train   6.286796e+09  16548.149805   \n",
       "3      2023-01-01 03:00:00     1.0  train   6.284575e+09  16533.632875   \n",
       "4      2023-01-01 04:00:00     2.0  train   6.291582e+09  16524.712159   \n",
       "...                    ...     ...    ...            ...           ...   \n",
       "11547  2024-04-26 03:00:00     NaN   test   1.486836e+10           NaN   \n",
       "11548  2024-04-26 04:00:00     NaN   test            NaN           NaN   \n",
       "11549  2024-04-26 05:00:00     NaN   test            NaN           NaN   \n",
       "11550  2024-04-26 06:00:00     NaN   test            NaN           NaN   \n",
       "11551  2024-04-26 07:00:00     NaN   test            NaN           NaN   \n",
       "\n",
       "         difficulty  supply_total   utxo_count  \n",
       "0      3.536407e+13  1.924871e+07   83308092.0  \n",
       "1      3.536407e+13  1.924874e+07   83314883.0  \n",
       "2      3.536407e+13  1.924879e+07   83314090.0  \n",
       "3      3.536407e+13  1.924882e+07   83326258.0  \n",
       "4      3.536407e+13  1.924886e+07   83339168.0  \n",
       "...             ...           ...          ...  \n",
       "11547  8.810419e+13           NaN  179820708.0  \n",
       "11548  8.810419e+13           NaN  179833897.0  \n",
       "11549  8.810419e+13           NaN  179851249.0  \n",
       "11550  8.810419e+13           NaN  179852452.0  \n",
       "11551  8.810419e+13           NaN          NaN  \n",
       "\n",
       "[11552 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _type에 따라 train, test 분리\n",
    "train_df = df.loc[df[\"_type\"]==\"train\"].drop(columns=[\"_type\"])\n",
    "test_df = df.loc[df[\"_type\"]==\"test\"].drop(columns=[\"_type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost 라이브러리에 구현되어 있는 XGBRegressor 모델을 사용하여 학습 및 평가를 진행합니다. xgboost의 래퍼 클래스(wrapper class) 중 **사이킷런 래퍼**를 사용할 예정입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model parameter (XGBRegressor)\n",
    "* n_estimator: 트리의 개수 (디폴트 = 100)  \n",
    "\n",
    "* learning_rate: 학습 단계별 가중치를 얼마나 사용할지(이전 결과를 얼마나 반영할 것인지) 결정. 일반적으로 0.01 ~ 0.2\n",
    "\n",
    "* max_depth: 트리의 최대 깊이. (디폴트 = 6) 일반적으로 3 ~ 10  \n",
    "\n",
    "* min_child_weight: child에서 필요한 모든 관측치에 대한 가중치의 최소 합. 이 값보다 샘플 수가 작으면 leaf node가 된다. 너무 큰 값을 적용하면 과소적합이 될 수 있다.  \n",
    "\n",
    "* early stopping_rounds: 최대한 몇 개의 트리를 완성해볼 것인지 결정. valid loss에 더 이상 진전이 없으면 멈춘다. n_estimator가 높을 때 주로 사용  \n",
    "\n",
    "* gamma: 트리에서 추가적으로 가지를 나눌지를 결정할 최소 손실 감소값. 값이 클수록 과적합 감소 효과  \n",
    "\n",
    "* subsample: 각 트리마다 데이터 샘플링 비율. (디폴트 = 1) 일반적으로 0.5 ~ 1  \n",
    "\n",
    "* colsample_bytree: 각 트리마다 feature 샘플링 비율. (디폴트 = 1) 일반적으로 0.5 ~ 1  \n",
    "\n",
    "* reg_lambda: L2 regularization 가중치 (디폴트 = 1)  \n",
    "\n",
    "* reg_alpha: L1 regularization 가중치 (디폴트 = 1)  \n",
    "\n",
    "* scale_pos_weight: 데이터가 불균형할때 사용, 0보다 큰 값. (디폴트 = 1) 보통 값을 (음성 데이터 수)/(양성 데이터 수) 값으로 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fit 파라미터\n",
    "\n",
    "* early_stopping_rounds:\n",
    "* eval_metric: \n",
    "* eval_set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop([\"ID\", \"target\", \"close\"], axis=1)\n",
    "y_train = train_df[\"close\"]\n",
    "target = train_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_to_class(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"close 변수를 target값으로 변환하는 함수입니다.\n",
    "\n",
    "    Args:\n",
    "        series (pd.Series): 변환을 원하는 close 변수\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: 변환된 target 값\n",
    "    \"\"\"\n",
    "    close = pd.DataFrame()\n",
    "    close['close'] = series\n",
    "    close['close_lag1'] = close['close'].shift(1)\n",
    "    close['close_lag1_percent'] = (close['close'] - close['close_lag1']) / close['close_lag1']\n",
    "    close['class'] = close['close']\n",
    "    for i in range(close.shape[0]):\n",
    "        if close.loc[i, 'close_lag1_percent'] < -0.005:\n",
    "            close.loc[i, 'class'] = 0\n",
    "        elif close.loc[i, 'close_lag1_percent'] < 0:\n",
    "            close.loc[i, 'class'] = 1\n",
    "        elif close.loc[i, 'close_lag1_percent'] < 0.005:\n",
    "            close.loc[i, 'class'] = 2\n",
    "        else:\n",
    "            close.loc[i, 'class'] = 3\n",
    "            \n",
    "    return close[\"class\"].shift(-1).fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "def evaluate(valid_target: pd.Series, \n",
    "             y_valid: pd.Series, \n",
    "             y_pred: np.ndarray, \n",
    "             metric: str\n",
    ") -> float:\n",
    "    \"\"\"평가지표 metric을 반환하는 함수입니다.\n",
    "\n",
    "    Args:\n",
    "        valid_target: (pd.Series): k-fold로 분할한 target의 검증 데이터\n",
    "        y_valid (pd.Series): k-fold로 분할한 close의 검증 데이터\n",
    "        y_pred (np.ndarray): 모델을 사용하여 예측한 변수\n",
    "        metric (str): 사용할 평가지표 metric 이름\n",
    "\n",
    "    Returns:\n",
    "        float: 사용할 평가지표 metric 값\n",
    "    \"\"\"\n",
    "    if metric == \"accuracy\":\n",
    "        classes = close_to_class(y_pred)\n",
    "        return accuracy_score(valid_target, classes)\n",
    "    elif metric == \"mae\":\n",
    "        return mean_absolute_error(y_valid, y_pred)\n",
    "    elif metric == \"mse\":\n",
    "        return mean_squared_error(y_valid, y_pred)\n",
    "    elif metric == \"mape\":\n",
    "        return mean_absolute_percentage_error(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model: Any, \n",
    "                X_train: pd.DataFrame, \n",
    "                y_train: pd.Series, \n",
    "                cv: int, \n",
    "                metric: str, \n",
    ") -> Tuple[Any, float]:\n",
    "    \"\"\"K-Fold로 데이터를 분할한 후 전처리를 거쳐 주어진 모델로 데이터를 학습 및 평가를 진행합니다.\n",
    "\n",
    "    Args:\n",
    "        model (Any): 사용하는 모델 객체\n",
    "        X_train (pd.DataFrame): 설명변수로 이루어진 학습 데이터프레임\n",
    "        y_train (pd.Seris): 예측변수로 이루어진 학습 시리즈\n",
    "        cv (int): 교차검증시 분할할 폴드의 수\n",
    "        metric (str): 사용할 평가지표 metric 이름\n",
    "\n",
    "    Returns:\n",
    "        Any, float: 폴드 내에서 가장 평가지표 값이 높은 모델 객체, 평가지표 metric 값\n",
    "    \"\"\"\n",
    "    kfold = KFold(n_splits=cv)\n",
    "    score_list = []\n",
    "    fold_model = []\n",
    "    \n",
    "    # warm_start는 모델의 속성으로, 같은 모델을 반복 학습할 때 이전 학습에서 학습된 파라미터를 초기화하지 않고 이어서 학습을 진행하는 옵션\n",
    "    if hasattr(model, \"warm_start\"):\n",
    "        model.warm_start = True\n",
    "\n",
    "    # K-Fold 교차 검증\n",
    "    for train_index, valid_index in kfold.split(X_train):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_valid, y_valid = X_train.iloc[valid_index], y_train.iloc[valid_index]\n",
    "\n",
    "        valid_target = target[valid_index]\n",
    "        \n",
    "        # 전처리\n",
    "        fill_feature(X_train_fold, method=\"mean\")\n",
    "        fill_feature(X_valid, method=\"mean\")        \n",
    "        \n",
    "        # 모델 학습\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        fold_model.append(model)\n",
    "\n",
    "        y_pred = model.predict(X_valid)\n",
    "        score = evaluate(valid_target, y_valid, y_pred, metric=metric)  # 평가지표 metric 반환\n",
    "        score_list.append(score)\n",
    "    \n",
    "    return fold_model[np.argmax(score_list)], np.max(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: int) -> float:\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1e-1),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 9),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 5),\n",
    "        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.3, 1.0),\n",
    "        \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
    "        \"device\": \"gpu\",\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "    \n",
    "    xgb_model = XGBRegressor(**params)\n",
    "    _, acc = model_train(xgb_model, X_train, y_train, cv=5, metric=\"accuracy\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-24 23:40:38,638] A new study created in memory with name: no-name-ba974344-cd4e-4370-999e-dcf8f5b68853\n",
      "[I 2024-09-24 23:40:42,866] Trial 0 finished with value: 0.4834474885844749 and parameters: {'n_estimators': 239, 'learning_rate': 0.012734312732365785, 'max_depth': 7, 'min_child_weight': 3, 'colsample_bytree': 0.9325599354349741, 'subsample': 0.5775280160091919}. Best is trial 0 with value: 0.4834474885844749.\n",
      "[I 2024-09-24 23:40:45,825] Trial 1 finished with value: 0.4891552511415525 and parameters: {'n_estimators': 126, 'learning_rate': 0.03054657345993057, 'max_depth': 6, 'min_child_weight': 5, 'colsample_bytree': 0.9591105963490665, 'subsample': 0.9916435070810459}. Best is trial 1 with value: 0.4891552511415525.\n",
      "[I 2024-09-24 23:40:48,932] Trial 2 finished with value: 0.4726027397260274 and parameters: {'n_estimators': 206, 'learning_rate': 0.004297907862527843, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.5311296574449774, 'subsample': 0.633218274052068}. Best is trial 1 with value: 0.4891552511415525.\n",
      "[I 2024-09-24 23:40:51,323] Trial 3 finished with value: 0.4834474885844749 and parameters: {'n_estimators': 59, 'learning_rate': 0.08043320655827621, 'max_depth': 5, 'min_child_weight': 5, 'colsample_bytree': 0.3268089659503261, 'subsample': 0.6683871225893618}. Best is trial 1 with value: 0.4891552511415525.\n",
      "[I 2024-09-24 23:40:55,828] Trial 4 finished with value: 0.4560502283105023 and parameters: {'n_estimators': 297, 'learning_rate': 0.042723977084186224, 'max_depth': 7, 'min_child_weight': 3, 'colsample_bytree': 0.8251232752117927, 'subsample': 0.6764903162339457}. Best is trial 1 with value: 0.4891552511415525.\n",
      "[I 2024-09-24 23:40:58,396] Trial 5 finished with value: 0.4686073059360731 and parameters: {'n_estimators': 99, 'learning_rate': 0.003941679916485476, 'max_depth': 3, 'min_child_weight': 3, 'colsample_bytree': 0.8194167461718997, 'subsample': 0.7692725492535744}. Best is trial 1 with value: 0.4891552511415525.\n",
      "[I 2024-09-24 23:41:02,014] Trial 6 finished with value: 0.4885844748858447 and parameters: {'n_estimators': 225, 'learning_rate': 0.009340318938422205, 'max_depth': 6, 'min_child_weight': 4, 'colsample_bytree': 0.5579637717277259, 'subsample': 0.7662404316143006}. Best is trial 1 with value: 0.4891552511415525.\n",
      "[I 2024-09-24 23:41:04,482] Trial 7 finished with value: 0.4731735159817352 and parameters: {'n_estimators': 67, 'learning_rate': 0.020657308549979415, 'max_depth': 5, 'min_child_weight': 4, 'colsample_bytree': 0.8533619147091454, 'subsample': 0.8725352804632094}. Best is trial 1 with value: 0.4891552511415525.\n",
      "[I 2024-09-24 23:41:07,027] Trial 8 finished with value: 0.4737442922374429 and parameters: {'n_estimators': 102, 'learning_rate': 0.0014854222253028117, 'max_depth': 4, 'min_child_weight': 3, 'colsample_bytree': 0.5974134255448891, 'subsample': 0.8167836027559755}. Best is trial 1 with value: 0.4891552511415525.\n",
      "[I 2024-09-24 23:41:10,178] Trial 9 finished with value: 0.4748858447488584 and parameters: {'n_estimators': 233, 'learning_rate': 0.028355182945402315, 'max_depth': 4, 'min_child_weight': 2, 'colsample_bytree': 0.8441305294061645, 'subsample': 0.6122114784776762}. Best is trial 1 with value: 0.4891552511415525.\n",
      "[I 2024-09-24 23:41:13,879] Trial 10 finished with value: 0.4606164383561644 and parameters: {'n_estimators': 140, 'learning_rate': 0.09698903320430832, 'max_depth': 9, 'min_child_weight': 5, 'colsample_bytree': 0.9820090961601469, 'subsample': 0.9961157060569492}. Best is trial 1 with value: 0.4891552511415525.\n",
      "[I 2024-09-24 23:41:17,278] Trial 11 finished with value: 0.4811643835616438 and parameters: {'n_estimators': 172, 'learning_rate': 0.008016383347472145, 'max_depth': 7, 'min_child_weight': 4, 'colsample_bytree': 0.46032850916469437, 'subsample': 0.9599541786547953}. Best is trial 1 with value: 0.4891552511415525.\n",
      "[I 2024-09-24 23:41:20,454] Trial 12 finished with value: 0.4743150684931507 and parameters: {'n_estimators': 159, 'learning_rate': 0.010548282308666763, 'max_depth': 6, 'min_child_weight': 5, 'colsample_bytree': 0.6969661261067958, 'subsample': 0.8958360795938016}. Best is trial 1 with value: 0.4891552511415525.\n",
      "[I 2024-09-24 23:41:25,174] Trial 13 finished with value: 0.4509132420091324 and parameters: {'n_estimators': 279, 'learning_rate': 0.040939673295253706, 'max_depth': 8, 'min_child_weight': 4, 'colsample_bytree': 0.6863330620681203, 'subsample': 0.7317892145511753}. Best is trial 1 with value: 0.4891552511415525.\n",
      "[I 2024-09-24 23:41:28,583] Trial 14 finished with value: 0.4960045662100457 and parameters: {'n_estimators': 203, 'learning_rate': 0.004411928572553274, 'max_depth': 6, 'min_child_weight': 4, 'colsample_bytree': 0.42116683844846825, 'subsample': 0.527874323617372}. Best is trial 14 with value: 0.4960045662100457.\n",
      "[I 2024-09-24 23:41:31,390] Trial 15 finished with value: 0.4988584474885845 and parameters: {'n_estimators': 127, 'learning_rate': 0.0010215251453071044, 'max_depth': 5, 'min_child_weight': 5, 'colsample_bytree': 0.32337866904112006, 'subsample': 0.5216752263989115}. Best is trial 15 with value: 0.4988584474885845.\n",
      "[I 2024-09-24 23:41:34,588] Trial 16 finished with value: 0.4994292237442922 and parameters: {'n_estimators': 200, 'learning_rate': 0.0013074109984741358, 'max_depth': 5, 'min_child_weight': 4, 'colsample_bytree': 0.30743644565920336, 'subsample': 0.5123053534279848}. Best is trial 16 with value: 0.4994292237442922.\n",
      "[I 2024-09-24 23:41:37,452] Trial 17 finished with value: 0.4920091324200913 and parameters: {'n_estimators': 193, 'learning_rate': 0.0012724875718810444, 'max_depth': 3, 'min_child_weight': 5, 'colsample_bytree': 0.31842099200864893, 'subsample': 0.5176091945759838}. Best is trial 16 with value: 0.4994292237442922.\n",
      "[I 2024-09-24 23:41:40,335] Trial 18 finished with value: 0.4965753424657534 and parameters: {'n_estimators': 146, 'learning_rate': 0.0023068650373202965, 'max_depth': 5, 'min_child_weight': 2, 'colsample_bytree': 0.420580264310807, 'subsample': 0.569078699983869}. Best is trial 16 with value: 0.4994292237442922.\n",
      "[I 2024-09-24 23:41:43,035] Trial 19 finished with value: 0.4994292237442922 and parameters: {'n_estimators': 112, 'learning_rate': 0.0010708337880396337, 'max_depth': 5, 'min_child_weight': 4, 'colsample_bytree': 0.3690641460458357, 'subsample': 0.5042093517542381}. Best is trial 16 with value: 0.4994292237442922.\n",
      "[I 2024-09-24 23:41:45,592] Trial 20 finished with value: 0.4920091324200913 and parameters: {'n_estimators': 98, 'learning_rate': 0.002383323042644374, 'max_depth': 4, 'min_child_weight': 2, 'colsample_bytree': 0.39447198587638904, 'subsample': 0.5724843819827724}. Best is trial 16 with value: 0.4994292237442922.\n",
      "[I 2024-09-24 23:41:48,326] Trial 21 finished with value: 0.5 and parameters: {'n_estimators': 120, 'learning_rate': 0.0010136527172388261, 'max_depth': 5, 'min_child_weight': 4, 'colsample_bytree': 0.3124420729961432, 'subsample': 0.5062727207551503}. Best is trial 21 with value: 0.5.\n",
      "[I 2024-09-24 23:41:50,884] Trial 22 finished with value: 0.4805936073059361 and parameters: {'n_estimators': 81, 'learning_rate': 0.0021658184066686123, 'max_depth': 5, 'min_child_weight': 4, 'colsample_bytree': 0.5004096172893573, 'subsample': 0.5063476539357085}. Best is trial 21 with value: 0.5.\n",
      "[I 2024-09-24 23:41:53,881] Trial 23 finished with value: 0.5034246575342466 and parameters: {'n_estimators': 181, 'learning_rate': 0.00174136875939863, 'max_depth': 4, 'min_child_weight': 4, 'colsample_bytree': 0.35425127662296607, 'subsample': 0.5737869616717596}. Best is trial 23 with value: 0.5034246575342466.\n",
      "[I 2024-09-24 23:41:56,874] Trial 24 finished with value: 0.4988584474885845 and parameters: {'n_estimators': 188, 'learning_rate': 0.0018225155294496894, 'max_depth': 4, 'min_child_weight': 4, 'colsample_bytree': 0.30763073565920923, 'subsample': 0.6062289151603877}. Best is trial 23 with value: 0.5034246575342466.\n",
      "[I 2024-09-24 23:41:59,637] Trial 25 finished with value: 0.4948630136986301 and parameters: {'n_estimators': 171, 'learning_rate': 0.0029854573191149788, 'max_depth': 3, 'min_child_weight': 3, 'colsample_bytree': 0.4643118008237443, 'subsample': 0.5530945931967752}. Best is trial 23 with value: 0.5034246575342466.\n",
      "[I 2024-09-24 23:42:02,913] Trial 26 finished with value: 0.5017123287671232 and parameters: {'n_estimators': 250, 'learning_rate': 0.0015884442984075403, 'max_depth': 4, 'min_child_weight': 3, 'colsample_bytree': 0.37882423086162886, 'subsample': 0.6694078851017115}. Best is trial 23 with value: 0.5034246575342466.\n",
      "[I 2024-09-24 23:42:06,021] Trial 27 finished with value: 0.4931506849315068 and parameters: {'n_estimators': 258, 'learning_rate': 0.006014383553264137, 'max_depth': 3, 'min_child_weight': 3, 'colsample_bytree': 0.3608919708101819, 'subsample': 0.6959197628585485}. Best is trial 23 with value: 0.5034246575342466.\n",
      "[I 2024-09-24 23:42:09,389] Trial 28 finished with value: 0.4777397260273973 and parameters: {'n_estimators': 265, 'learning_rate': 0.003211093208888064, 'max_depth': 4, 'min_child_weight': 2, 'colsample_bytree': 0.6298695549518594, 'subsample': 0.6400574202530152}. Best is trial 23 with value: 0.5034246575342466.\n",
      "[I 2024-09-24 23:42:12,435] Trial 29 finished with value: 0.4891552511415525 and parameters: {'n_estimators': 243, 'learning_rate': 0.001704249867582157, 'max_depth': 3, 'min_child_weight': 3, 'colsample_bytree': 0.46745029847274755, 'subsample': 0.5997428803500912}. Best is trial 23 with value: 0.5034246575342466.\n",
      "[I 2024-09-24 23:42:15,593] Trial 30 finished with value: 0.5062785388127854 and parameters: {'n_estimators': 219, 'learning_rate': 0.01517865022744374, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.37426200566411644, 'subsample': 0.7175849137283077}. Best is trial 30 with value: 0.5062785388127854.\n",
      "[I 2024-09-24 23:42:18,763] Trial 31 finished with value: 0.5028538812785388 and parameters: {'n_estimators': 218, 'learning_rate': 0.016444221176458277, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.3776209306022812, 'subsample': 0.718834417481068}. Best is trial 30 with value: 0.5062785388127854.\n",
      "[I 2024-09-24 23:42:21,862] Trial 32 finished with value: 0.5091324200913242 and parameters: {'n_estimators': 217, 'learning_rate': 0.015324709664710327, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.3879120963422991, 'subsample': 0.7383620752662649}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:42:24,997] Trial 33 finished with value: 0.5034246575342466 and parameters: {'n_estimators': 219, 'learning_rate': 0.01652307135157985, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.41365903945749405, 'subsample': 0.7255564175120488}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:42:27,819] Trial 34 finished with value: 0.4851598173515982 and parameters: {'n_estimators': 183, 'learning_rate': 0.015053520332952664, 'max_depth': 3, 'min_child_weight': 1, 'colsample_bytree': 0.5197707994134282, 'subsample': 0.7994939747977633}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:42:30,949] Trial 35 finished with value: 0.4931506849315068 and parameters: {'n_estimators': 223, 'learning_rate': 0.023620686360313402, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.4237050831293447, 'subsample': 0.8453026327930305}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:42:33,894] Trial 36 finished with value: 0.4823059360730594 and parameters: {'n_estimators': 215, 'learning_rate': 0.012843701440140685, 'max_depth': 3, 'min_child_weight': 1, 'colsample_bytree': 0.5540553418345188, 'subsample': 0.7002822033490537}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:42:37,302] Trial 37 finished with value: 0.4948630136986301 and parameters: {'n_estimators': 236, 'learning_rate': 0.006514305749945002, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.3537233039300034, 'subsample': 0.7507547771490285}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:42:41,025] Trial 38 finished with value: 0.4748858447488584 and parameters: {'n_estimators': 209, 'learning_rate': 0.042722109577154464, 'max_depth': 7, 'min_child_weight': 1, 'colsample_bytree': 0.488410215705385, 'subsample': 0.7973965080437035}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:42:44,432] Trial 39 finished with value: 0.4954337899543379 and parameters: {'n_estimators': 277, 'learning_rate': 0.018828647527877124, 'max_depth': 4, 'min_child_weight': 2, 'colsample_bytree': 0.4363335112836735, 'subsample': 0.6418454446821428}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:42:47,751] Trial 40 finished with value: 0.4646118721461187 and parameters: {'n_estimators': 178, 'learning_rate': 0.029742758904834805, 'max_depth': 6, 'min_child_weight': 1, 'colsample_bytree': 0.579144182914919, 'subsample': 0.7813368645849903}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:42:50,914] Trial 41 finished with value: 0.5057077625570776 and parameters: {'n_estimators': 229, 'learning_rate': 0.015799421018073107, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.3901187978486697, 'subsample': 0.7156419089349676}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:42:54,079] Trial 42 finished with value: 0.4971461187214612 and parameters: {'n_estimators': 230, 'learning_rate': 0.011600362661528684, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.3989145075178708, 'subsample': 0.7340213718779771}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:42:57,246] Trial 43 finished with value: 0.4954337899543379 and parameters: {'n_estimators': 196, 'learning_rate': 0.008403555508444094, 'max_depth': 5, 'min_child_weight': 2, 'colsample_bytree': 0.3525546334677391, 'subsample': 0.699272559591129}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:42:59,946] Trial 44 finished with value: 0.4817351598173516 and parameters: {'n_estimators': 157, 'learning_rate': 0.06176480430417994, 'max_depth': 3, 'min_child_weight': 1, 'colsample_bytree': 0.7668905606999712, 'subsample': 0.7582705604306599}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:43:03,037] Trial 45 finished with value: 0.4828767123287671 and parameters: {'n_estimators': 209, 'learning_rate': 0.022589864854156292, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.9128235718593591, 'subsample': 0.654332686661572}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:43:06,745] Trial 46 finished with value: 0.4691780821917808 and parameters: {'n_estimators': 251, 'learning_rate': 0.014087609740626488, 'max_depth': 6, 'min_child_weight': 2, 'colsample_bytree': 0.44868949111389345, 'subsample': 0.8290514173487925}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:43:11,064] Trial 47 finished with value: 0.4691780821917808 and parameters: {'n_estimators': 226, 'learning_rate': 0.03473842925259463, 'max_depth': 9, 'min_child_weight': 1, 'colsample_bytree': 0.33965341299396284, 'subsample': 0.6841291408573696}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:43:14,270] Trial 48 finished with value: 0.4925799086757991 and parameters: {'n_estimators': 239, 'learning_rate': 0.017521172363815916, 'max_depth': 4, 'min_child_weight': 2, 'colsample_bytree': 0.4072394431754661, 'subsample': 0.9055183561084157}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:43:17,325] Trial 49 finished with value: 0.4857305936073059 and parameters: {'n_estimators': 167, 'learning_rate': 0.009793503128778852, 'max_depth': 5, 'min_child_weight': 1, 'colsample_bytree': 0.5022878513958975, 'subsample': 0.7332650954236919}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:43:20,588] Trial 50 finished with value: 0.4800228310502283 and parameters: {'n_estimators': 295, 'learning_rate': 0.006988598331874861, 'max_depth': 3, 'min_child_weight': 1, 'colsample_bytree': 0.5418729683038936, 'subsample': 0.714948859645547}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:43:23,680] Trial 51 finished with value: 0.5028538812785388 and parameters: {'n_estimators': 213, 'learning_rate': 0.01683053232435358, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.38414189439462443, 'subsample': 0.7161016392728125}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:43:26,793] Trial 52 finished with value: 0.4948630136986301 and parameters: {'n_estimators': 219, 'learning_rate': 0.02555425295318758, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.3824344539127229, 'subsample': 0.7773726605657505}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:43:30,000] Trial 53 finished with value: 0.4931506849315068 and parameters: {'n_estimators': 202, 'learning_rate': 0.005285430035327023, 'max_depth': 5, 'min_child_weight': 1, 'colsample_bytree': 0.3364064497027829, 'subsample': 0.6630206456968427}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:43:33,033] Trial 54 finished with value: 0.4971461187214612 and parameters: {'n_estimators': 191, 'learning_rate': 0.01105256636168741, 'max_depth': 4, 'min_child_weight': 2, 'colsample_bytree': 0.44534375505008506, 'subsample': 0.7205616541886546}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:43:36,328] Trial 55 finished with value: 0.507420091324201 and parameters: {'n_estimators': 228, 'learning_rate': 0.015262538781933866, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.4133817722694514, 'subsample': 0.6216487454723079}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:43:40,499] Trial 56 finished with value: 0.4708904109589041 and parameters: {'n_estimators': 243, 'learning_rate': 0.019185056232284555, 'max_depth': 8, 'min_child_weight': 1, 'colsample_bytree': 0.4808598372103448, 'subsample': 0.5835648634091015}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:43:43,879] Trial 57 finished with value: 0.4931506849315068 and parameters: {'n_estimators': 234, 'learning_rate': 0.013058215720725101, 'max_depth': 5, 'min_child_weight': 2, 'colsample_bytree': 0.4190744561705894, 'subsample': 0.6198220131060005}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:43:47,026] Trial 58 finished with value: 0.4937214611872146 and parameters: {'n_estimators': 267, 'learning_rate': 0.03469985418930891, 'max_depth': 3, 'min_child_weight': 1, 'colsample_bytree': 0.3336570783312307, 'subsample': 0.5537761955972845}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:43:50,228] Trial 59 finished with value: 0.4994292237442922 and parameters: {'n_estimators': 201, 'learning_rate': 0.008257951614447163, 'max_depth': 5, 'min_child_weight': 5, 'colsample_bytree': 0.3030174724572854, 'subsample': 0.6837074100783227}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:43:53,565] Trial 60 finished with value: 0.478310502283105 and parameters: {'n_estimators': 252, 'learning_rate': 0.05756378853848388, 'max_depth': 4, 'min_child_weight': 2, 'colsample_bytree': 0.752285405887287, 'subsample': 0.7468228216678942}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:43:56,668] Trial 61 finished with value: 0.5005707762557078 and parameters: {'n_estimators': 218, 'learning_rate': 0.01583886189561918, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.3949438547198692, 'subsample': 0.624439068291981}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:43:59,821] Trial 62 finished with value: 0.490296803652968 and parameters: {'n_estimators': 224, 'learning_rate': 0.021855158951370992, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.36894501909602573, 'subsample': 0.5377680414045107}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:44:02,751] Trial 63 finished with value: 0.4925799086757991 and parameters: {'n_estimators': 181, 'learning_rate': 0.02692986707336832, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.4303810980880577, 'subsample': 0.7687554261706555}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:44:05,735] Trial 64 finished with value: 0.4931506849315068 and parameters: {'n_estimators': 229, 'learning_rate': 0.011706117044268095, 'max_depth': 3, 'min_child_weight': 1, 'colsample_bytree': 0.35514725766477073, 'subsample': 0.5924924396879434}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:44:08,781] Trial 65 finished with value: 0.5 and parameters: {'n_estimators': 206, 'learning_rate': 0.020344999555569378, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.40190949614083, 'subsample': 0.7452973047227073}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:44:11,427] Trial 66 finished with value: 0.4931506849315068 and parameters: {'n_estimators': 141, 'learning_rate': 0.015082396742843266, 'max_depth': 3, 'min_child_weight': 1, 'colsample_bytree': 0.45325563714750805, 'subsample': 0.7124040588239726}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:44:14,881] Trial 67 finished with value: 0.4925799086757991 and parameters: {'n_estimators': 246, 'learning_rate': 0.009898399642807235, 'max_depth': 5, 'min_child_weight': 2, 'colsample_bytree': 0.3786648896015068, 'subsample': 0.6796636250334596}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:44:17,884] Trial 68 finished with value: 0.490296803652968 and parameters: {'n_estimators': 189, 'learning_rate': 0.017302856528520993, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.5122164027986833, 'subsample': 0.6535953657399121}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:44:22,189] Trial 69 finished with value: 0.466324200913242 and parameters: {'n_estimators': 258, 'learning_rate': 0.012968226244109557, 'max_depth': 8, 'min_child_weight': 1, 'colsample_bytree': 0.47112752013999687, 'subsample': 0.787850302179198}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:44:25,280] Trial 70 finished with value: 0.4977168949771689 and parameters: {'n_estimators': 214, 'learning_rate': 0.015145374396448242, 'max_depth': 4, 'min_child_weight': 3, 'colsample_bytree': 0.3353735119700704, 'subsample': 0.8148042315912938}. Best is trial 32 with value: 0.5091324200913242.\n",
      "[I 2024-09-24 23:44:28,359] Trial 71 finished with value: 0.5108447488584474 and parameters: {'n_estimators': 209, 'learning_rate': 0.01754585801595732, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.3898804698141874, 'subsample': 0.7188595443305431}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:44:31,464] Trial 72 finished with value: 0.502283105022831 and parameters: {'n_estimators': 196, 'learning_rate': 0.019176604640567245, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.40645595877121765, 'subsample': 0.731518733126774}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:44:34,800] Trial 73 finished with value: 0.4828767123287671 and parameters: {'n_estimators': 221, 'learning_rate': 0.02468317848761415, 'max_depth': 5, 'min_child_weight': 1, 'colsample_bytree': 0.3697157280356331, 'subsample': 0.6981819545607432}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:44:37,809] Trial 74 finished with value: 0.4960045662100457 and parameters: {'n_estimators': 234, 'learning_rate': 0.009093094914770882, 'max_depth': 3, 'min_child_weight': 1, 'colsample_bytree': 0.42623331305758455, 'subsample': 0.7624588272501297}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:44:40,881] Trial 75 finished with value: 0.5051369863013698 and parameters: {'n_estimators': 209, 'learning_rate': 0.014068774295087365, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.35071149181814004, 'subsample': 0.7229791904049847}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:44:43,744] Trial 76 finished with value: 0.4988584474885845 and parameters: {'n_estimators': 165, 'learning_rate': 0.011255781173314805, 'max_depth': 4, 'min_child_weight': 5, 'colsample_bytree': 0.3194198342989208, 'subsample': 0.5626238415301342}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:44:46,813] Trial 77 finished with value: 0.507420091324201 and parameters: {'n_estimators': 209, 'learning_rate': 0.013831620683703976, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.3496191192839995, 'subsample': 0.7428813261959812}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:44:49,951] Trial 78 finished with value: 0.4948630136986301 and parameters: {'n_estimators': 186, 'learning_rate': 0.007598873356338268, 'max_depth': 5, 'min_child_weight': 1, 'colsample_bytree': 0.3569636123975728, 'subsample': 0.7422479414609705}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:44:53,013] Trial 79 finished with value: 0.5005707762557078 and parameters: {'n_estimators': 206, 'learning_rate': 0.005526124175908049, 'max_depth': 4, 'min_child_weight': 4, 'colsample_bytree': 0.3400898637336891, 'subsample': 0.707206624998154}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:44:55,771] Trial 80 finished with value: 0.4948630136986301 and parameters: {'n_estimators': 154, 'learning_rate': 0.01388484974482246, 'max_depth': 3, 'min_child_weight': 1, 'colsample_bytree': 0.3190888802321159, 'subsample': 0.6897280898889868}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:44:58,869] Trial 81 finished with value: 0.4988584474885845 and parameters: {'n_estimators': 211, 'learning_rate': 0.012053596257028986, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.4068914556941092, 'subsample': 0.7567473146657471}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:45:02,027] Trial 82 finished with value: 0.4874429223744292 and parameters: {'n_estimators': 230, 'learning_rate': 0.021933119216120043, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.35094184836056447, 'subsample': 0.7268623993234262}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:45:04,961] Trial 83 finished with value: 0.5011415525114156 and parameters: {'n_estimators': 176, 'learning_rate': 0.018002473058775254, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.38614405803582713, 'subsample': 0.6619673233464214}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:45:08,213] Trial 84 finished with value: 0.4925799086757991 and parameters: {'n_estimators': 240, 'learning_rate': 0.014033664491779176, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.648534729559053, 'subsample': 0.533063738833171}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:45:11,452] Trial 85 finished with value: 0.4834474885844749 and parameters: {'n_estimators': 196, 'learning_rate': 0.009258154880134135, 'max_depth': 5, 'min_child_weight': 1, 'colsample_bytree': 0.44276022137625, 'subsample': 0.9668708914474962}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:45:14,583] Trial 86 finished with value: 0.507420091324201 and parameters: {'n_estimators': 223, 'learning_rate': 0.016087061632563005, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.3001622071036393, 'subsample': 0.7905390499273627}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:45:17,598] Trial 87 finished with value: 0.488013698630137 and parameters: {'n_estimators': 226, 'learning_rate': 0.010383265476906661, 'max_depth': 3, 'min_child_weight': 1, 'colsample_bytree': 0.30750125372994025, 'subsample': 0.8093046704524042}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:45:20,657] Trial 88 finished with value: 0.4937214611872146 and parameters: {'n_estimators': 202, 'learning_rate': 0.03410577272033881, 'max_depth': 4, 'min_child_weight': 2, 'colsample_bytree': 0.3239592340080845, 'subsample': 0.8347232968399911}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:45:23,735] Trial 89 finished with value: 0.4977168949771689 and parameters: {'n_estimators': 212, 'learning_rate': 0.020607467287368075, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.36378830640554566, 'subsample': 0.8765496103649073}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:45:26,738] Trial 90 finished with value: 0.4931506849315068 and parameters: {'n_estimators': 235, 'learning_rate': 0.0037259243726024353, 'max_depth': 3, 'min_child_weight': 1, 'colsample_bytree': 0.3479265398530414, 'subsample': 0.7770408293782236}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:45:29,873] Trial 91 finished with value: 0.5051369863013698 and parameters: {'n_estimators': 219, 'learning_rate': 0.016914151431545257, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.41194203606710467, 'subsample': 0.7391836297755082}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:45:33,001] Trial 92 finished with value: 0.4994292237442922 and parameters: {'n_estimators': 222, 'learning_rate': 0.014193837828910658, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.3912798851371154, 'subsample': 0.7926882168472392}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:45:36,107] Trial 93 finished with value: 0.5068493150684932 and parameters: {'n_estimators': 216, 'learning_rate': 0.015928687969568776, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.3657680636403482, 'subsample': 0.737707471222708}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:45:39,192] Trial 94 finished with value: 0.5108447488584474 and parameters: {'n_estimators': 216, 'learning_rate': 0.01654603369709793, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.37073758590679434, 'subsample': 0.7525195958617819}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:45:42,253] Trial 95 finished with value: 0.5011415525114156 and parameters: {'n_estimators': 209, 'learning_rate': 0.012811563688903542, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.32720080807820207, 'subsample': 0.7558959510913882}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:45:45,481] Trial 96 finished with value: 0.4988584474885845 and parameters: {'n_estimators': 246, 'learning_rate': 0.018991638693963146, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.3648837476132379, 'subsample': 0.7680099037638994}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:45:48,868] Trial 97 finished with value: 0.4817351598173516 and parameters: {'n_estimators': 226, 'learning_rate': 0.015836537539705417, 'max_depth': 5, 'min_child_weight': 1, 'colsample_bytree': 0.30162656113071934, 'subsample': 0.7260142873425225}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:45:51,879] Trial 98 finished with value: 0.4982876712328767 and parameters: {'n_estimators': 197, 'learning_rate': 0.028839373337993343, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.37464740422371623, 'subsample': 0.7071558094758087}. Best is trial 71 with value: 0.5108447488584474.\n",
      "[I 2024-09-24 23:45:54,955] Trial 99 finished with value: 0.4948630136986301 and parameters: {'n_estimators': 215, 'learning_rate': 0.023710429740389744, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.3925856630331056, 'subsample': 0.8007466065129816}. Best is trial 71 with value: 0.5108447488584474.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'n_estimators': 209, 'learning_rate': 0.01754585801595732, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.3898804698141874, 'subsample': 0.7188595443305431}\n",
      "XGBoost model accuracy: 0.5108447488584474\n"
     ]
    }
   ],
   "source": [
    "# Optuna study 생성 및 최적화 실행\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"Best Hyperparameters: \", study.best_params)\n",
    "\n",
    "# 최적의 하이퍼파라미터를 사용하여 최종 모델 생성\n",
    "best_params = study.best_params\n",
    "best_params[\"device\"] = \"gpu\"\n",
    "best_params[\"random_state\"] = 42\n",
    "best_xgb_model = XGBRegressor(**best_params)\n",
    "\n",
    "# 최종 모델 평가\n",
    "fold_best_xgb_model, acc = model_train(best_xgb_model, X_train, y_train, cv=5, metric=\"accuracy\")\n",
    "print(f\"XGBoost model accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold_best_xgb_model이 학습 데이터 전체를 학습할 수 있도록 결측치 처리\n",
    "X_train = fill_feature(X_train, method=\"mean\")\n",
    "X_test = test_df.drop([\"ID\", \"target\", \"close\"], axis=1)\n",
    "X_test = fill_feature(X_test, method=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 전체로 fold_best_xgb_model 학습\n",
    "fold_best_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# close 예측값 생성\n",
    "y_test_pred = fold_best_xgb_model.predict(X_test)\n",
    "\n",
    "# close 예측값을 등락폭에 따라 범주화\n",
    "y_test_pred_class = close_to_class(y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output File Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output file 할당후 save \n",
    "submission_df = submission_df.assign(target = y_test_pred_class)\n",
    "submission_df[\"target\"] = submission_df[\"target\"].astype(np.int8)\n",
    "submission_df.to_csv(\"output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pd.read_csv(\"output.csv\")\n",
    "out[\"target\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "2    2567\n",
      "1      94\n",
      "3      67\n",
      "0      64\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "target\n",
      "2    0.919413\n",
      "1    0.033668\n",
      "3    0.023997\n",
      "0    0.022923\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(out[\"target\"].value_counts(), '\\n')\n",
    "print(out[\"target\"].value_counts() / len(out[\"target\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-lecture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
