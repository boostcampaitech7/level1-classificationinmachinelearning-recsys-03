{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:15: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Any, List, Dict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "from data_preprocessing import *\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 호출\n",
    "data_path: str = \"/data/ephemeral/home/BTC/data\"\n",
    "train_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"train.csv\")).assign(_type=\"train\") # train 에는 _type = train \n",
    "test_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"test.csv\")).assign(_type=\"test\") # test 에는 _type = test\n",
    "submission_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"test.csv\")) # ID, target 열만 가진 데이터 미리 호출\n",
    "df: pd.DataFrame = pd.concat([train_df, test_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:03<00:00, 32.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# HOURLY_ 로 시작하는 .csv 파일 이름을 file_names 에 할딩\n",
    "file_names: List[str] = [\n",
    "    f for f in os.listdir(data_path) if f.startswith(\"HOURLY_\") and f.endswith(\".csv\")\n",
    "]\n",
    "\n",
    "# 파일명 : 데이터프레임으로 딕셔너리 형태로 저장\n",
    "file_dict: Dict[str, pd.DataFrame] = {\n",
    "    f.replace(\".csv\", \"\"): pd.read_csv(os.path.join(data_path, f)) for f in file_names\n",
    "}\n",
    "\n",
    "for _file_name, _df in tqdm(file_dict.items()):\n",
    "    # 열 이름 중복 방지를 위해 {_file_name.lower()}_{col.lower()}로 변경, datetime 열을 ID로 변경\n",
    "    _rename_rule = {\n",
    "        col: f\"{_file_name.lower()}_{col.lower()}\" if col != \"datetime\" else \"ID\"\n",
    "        for col in _df.columns\n",
    "    }\n",
    "    _df = _df.rename(_rename_rule, axis=1)\n",
    "    df = df.merge(_df, on=\"ID\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA (Explanatory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11552, 43)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델에 사용할 컬럼, 컬럼의 rename rule을 미리 할당함\n",
    "cols_dict: Dict[str, str] = {\n",
    "    \"ID\": \"ID\",\n",
    "    \"target\": \"target\",\n",
    "    \"_type\" : \"_type\",\n",
    "    \"hourly_market-data_funding-rates_all_exchange_funding_rates\": \"funding_rates\",\n",
    "    \"hourly_market-data_liquidations_all_exchange_all_symbol_long_liquidations\": \"long_liquidations\",\n",
    "    \"hourly_market-data_liquidations_all_exchange_all_symbol_short_liquidations\": \"short_liquidations\",\n",
    "    \"hourly_market-data_liquidations_all_exchange_all_symbol_long_liquidations_usd\": \"long_liquidations_usd\",\n",
    "    \"hourly_market-data_liquidations_all_exchange_all_symbol_short_liquidations_usd\": \"short_liquidations_usd\",\n",
    "    \"hourly_market-data_open-interest_all_exchange_all_symbol_open_interest\": \"open_interest\",\n",
    "    \"hourly_market-data_price-ohlcv_all_exchange_spot_btc_usd_close\": \"close\",\n",
    "    \"hourly_market-data_taker-buy-sell-stats_all_exchange_taker_buy_volume\": \"taker_buy_volume\",\n",
    "    \"hourly_market-data_taker-buy-sell-stats_all_exchange_taker_sell_volume\": \"taker_sell_volume\",\n",
    "    \"hourly_market-data_taker-buy-sell-stats_all_exchange_taker_buy_ratio\": \"taker_buy_ratio\",\n",
    "    \"hourly_market-data_taker-buy-sell-stats_all_exchange_taker_sell_ratio\": \"taker_sell_ratio\",\n",
    "    \"hourly_market-data_taker-buy-sell-stats_all_exchange_taker_buy_sell_ratio\": \"taker_buy_sell_ratio\",\n",
    "    \"hourly_network-data_addresses-count_addresses_count_active\": \"addresses_count_active\",\n",
    "    \"hourly_network-data_addresses-count_addresses_count_sender\": \"addresses_count_sender\",\n",
    "    \"hourly_network-data_addresses-count_addresses_count_receiver\": \"addresses_count_receiver\",\n",
    "    \"hourly_network-data_block-bytes_block_bytes\": \"block_bytes\",\n",
    "    \"hourly_network-data_block-count_block_count\": \"block_count\",\n",
    "    \"hourly_network-data_block-interval_block_interval\": \"block_interval\",\n",
    "    \"hourly_network-data_blockreward_blockreward\": \"blockreward\",\n",
    "    \"hourly_network-data_blockreward_blockreward_usd\": \"blockreward_usd\",\n",
    "    \"hourly_network-data_difficulty_difficulty\": \"difficulty\",\n",
    "    \"hourly_network-data_fees_fees_block_mean\": \"fees_block_mean\",\n",
    "    \"hourly_network-data_fees_fees_block_mean_usd\": \"fees_block_mean_usd\",\n",
    "    \"hourly_network-data_fees_fees_total\": \"fees_total\",\n",
    "    \"hourly_network-data_fees_fees_total_usd\": \"fees_total_usd\",\n",
    "    \"hourly_network-data_fees_fees_reward_percent\": \"fees_reward_percent\",\n",
    "    \"hourly_network-data_fees-transaction_fees_transaction_mean\": \"fees_transaction_mean\",\n",
    "    \"hourly_network-data_fees-transaction_fees_transaction_mean_usd\": \"fees_transaction_mean_usd\",\n",
    "    \"hourly_network-data_fees-transaction_fees_transaction_median\": \"fees_transaction_median\",\n",
    "    \"hourly_network-data_fees-transaction_fees_transaction_median_usd\": \"fees_transaction_median_usd\",\n",
    "    \"hourly_network-data_hashrate_hashrate\": \"hashrate\",\n",
    "    \"hourly_network-data_supply_supply_total\": \"supply_total\",\n",
    "    \"hourly_network-data_supply_supply_new\": \"supply_new\",\n",
    "    \"hourly_network-data_tokens-transferred_tokens_transferred_total\": \"tokens_transferred_total\",\n",
    "    \"hourly_network-data_tokens-transferred_tokens_transferred_mean\": \"tokens_transferred_mean\",\n",
    "    \"hourly_network-data_tokens-transferred_tokens_transferred_median\": \"tokens_transferred_median\",\n",
    "    \"hourly_network-data_transactions-count_transactions_count_total\": \"transactions_count_total\",\n",
    "    \"hourly_network-data_transactions-count_transactions_count_mean\": \"transactions_count_mean\",\n",
    "    \"hourly_network-data_utxo-count_utxo_count\": \"utxo_count\",\n",
    "    \"hourly_network-data_velocity_velocity_supply_total\": \"velocity_supply_total\"\n",
    "}\n",
    "df = df[cols_dict.keys()].rename(cols_dict, axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continuous 열을 따로 할당해둠\n",
    "conti_cols: List[str] = [\n",
    "    \"close\",\n",
    "    \"open_interest\",\n",
    "    \"difficulty\",\n",
    "    \"supply_total\",\n",
    "    \"utxo_count\"\n",
    "]\n",
    "\n",
    "# 최대 24시간의 shift 피쳐를 계산\n",
    "shift_list = shift_feature(\n",
    "    df=df, conti_cols=conti_cols, intervals=[_ for _ in range(1, 24)]\n",
    ")\n",
    "\n",
    "# concat 하여 df 에 할당\n",
    "df = pd.concat([df, pd.concat(shift_list, axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>_type</th>\n",
       "      <th>funding_rates</th>\n",
       "      <th>long_liquidations</th>\n",
       "      <th>short_liquidations</th>\n",
       "      <th>long_liquidations_usd</th>\n",
       "      <th>short_liquidations_usd</th>\n",
       "      <th>open_interest</th>\n",
       "      <th>close</th>\n",
       "      <th>...</th>\n",
       "      <th>utxo_count_14</th>\n",
       "      <th>utxo_count_15</th>\n",
       "      <th>utxo_count_16</th>\n",
       "      <th>utxo_count_17</th>\n",
       "      <th>utxo_count_18</th>\n",
       "      <th>utxo_count_19</th>\n",
       "      <th>utxo_count_20</th>\n",
       "      <th>utxo_count_21</th>\n",
       "      <th>utxo_count_22</th>\n",
       "      <th>utxo_count_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>197.51610</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.271344e+09</td>\n",
       "      <td>16536.747967</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11833.56104</td>\n",
       "      <td>6.288683e+09</td>\n",
       "      <td>16557.136536</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 02:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.286796e+09</td>\n",
       "      <td>16548.149805</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 03:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.005067</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9754.76891</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.284575e+09</td>\n",
       "      <td>16533.632875</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 04:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.006210</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5944.43714</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.291582e+09</td>\n",
       "      <td>16524.712159</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11547</th>\n",
       "      <td>2024-04-26 03:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.243500</td>\n",
       "      <td>45484.20433</td>\n",
       "      <td>15682.76464</td>\n",
       "      <td>1.486836e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>179565695.0</td>\n",
       "      <td>179552815.0</td>\n",
       "      <td>179543052.0</td>\n",
       "      <td>179504816.0</td>\n",
       "      <td>179479822.0</td>\n",
       "      <td>179474550.0</td>\n",
       "      <td>179469208.0</td>\n",
       "      <td>179467442.0</td>\n",
       "      <td>179463219.0</td>\n",
       "      <td>179459713.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11548</th>\n",
       "      <td>2024-04-26 04:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.577208</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>420718.03779</td>\n",
       "      <td>9419.65430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>179575936.0</td>\n",
       "      <td>179565695.0</td>\n",
       "      <td>179552815.0</td>\n",
       "      <td>179543052.0</td>\n",
       "      <td>179504816.0</td>\n",
       "      <td>179479822.0</td>\n",
       "      <td>179474550.0</td>\n",
       "      <td>179469208.0</td>\n",
       "      <td>179467442.0</td>\n",
       "      <td>179463219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11549</th>\n",
       "      <td>2024-04-26 05:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.797163</td>\n",
       "      <td>5.216490</td>\n",
       "      <td>114902.59095</td>\n",
       "      <td>337367.12807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>179593285.0</td>\n",
       "      <td>179575936.0</td>\n",
       "      <td>179565695.0</td>\n",
       "      <td>179552815.0</td>\n",
       "      <td>179543052.0</td>\n",
       "      <td>179504816.0</td>\n",
       "      <td>179479822.0</td>\n",
       "      <td>179474550.0</td>\n",
       "      <td>179469208.0</td>\n",
       "      <td>179467442.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11550</th>\n",
       "      <td>2024-04-26 06:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.803000</td>\n",
       "      <td>1.656000</td>\n",
       "      <td>51434.51531</td>\n",
       "      <td>106931.54104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>179602579.0</td>\n",
       "      <td>179593285.0</td>\n",
       "      <td>179575936.0</td>\n",
       "      <td>179565695.0</td>\n",
       "      <td>179552815.0</td>\n",
       "      <td>179543052.0</td>\n",
       "      <td>179504816.0</td>\n",
       "      <td>179479822.0</td>\n",
       "      <td>179474550.0</td>\n",
       "      <td>179469208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11551</th>\n",
       "      <td>2024-04-26 07:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.360383</td>\n",
       "      <td>3.930057</td>\n",
       "      <td>151151.38884</td>\n",
       "      <td>253858.89276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>179630514.0</td>\n",
       "      <td>179602579.0</td>\n",
       "      <td>179593285.0</td>\n",
       "      <td>179575936.0</td>\n",
       "      <td>179565695.0</td>\n",
       "      <td>179552815.0</td>\n",
       "      <td>179543052.0</td>\n",
       "      <td>179504816.0</td>\n",
       "      <td>179479822.0</td>\n",
       "      <td>179474550.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11552 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID  target  _type  funding_rates  long_liquidations  \\\n",
       "0      2023-01-01 00:00:00     2.0  train       0.005049           0.012000   \n",
       "1      2023-01-01 01:00:00     1.0  train       0.005049           0.000000   \n",
       "2      2023-01-01 02:00:00     1.0  train       0.005049           0.000000   \n",
       "3      2023-01-01 03:00:00     1.0  train       0.005067           0.593000   \n",
       "4      2023-01-01 04:00:00     2.0  train       0.006210           0.361000   \n",
       "...                    ...     ...    ...            ...                ...   \n",
       "11547  2024-04-26 03:00:00     NaN   test            NaN           0.710000   \n",
       "11548  2024-04-26 04:00:00     NaN   test            NaN           6.577208   \n",
       "11549  2024-04-26 05:00:00     NaN   test            NaN           1.797163   \n",
       "11550  2024-04-26 06:00:00     NaN   test            NaN           0.803000   \n",
       "11551  2024-04-26 07:00:00     NaN   test            NaN           2.360383   \n",
       "\n",
       "       short_liquidations  long_liquidations_usd  short_liquidations_usd  \\\n",
       "0                0.000000              197.51610                 0.00000   \n",
       "1                0.712000                0.00000             11833.56104   \n",
       "2                0.000000                0.00000                 0.00000   \n",
       "3                0.000000             9754.76891                 0.00000   \n",
       "4                0.000000             5944.43714                 0.00000   \n",
       "...                   ...                    ...                     ...   \n",
       "11547            0.243500            45484.20433             15682.76464   \n",
       "11548            0.146000           420718.03779              9419.65430   \n",
       "11549            5.216490           114902.59095            337367.12807   \n",
       "11550            1.656000            51434.51531            106931.54104   \n",
       "11551            3.930057           151151.38884            253858.89276   \n",
       "\n",
       "       open_interest         close  ...  utxo_count_14  utxo_count_15  \\\n",
       "0       6.271344e+09  16536.747967  ...            NaN            NaN   \n",
       "1       6.288683e+09  16557.136536  ...            NaN            NaN   \n",
       "2       6.286796e+09  16548.149805  ...            NaN            NaN   \n",
       "3       6.284575e+09  16533.632875  ...            NaN            NaN   \n",
       "4       6.291582e+09  16524.712159  ...            NaN            NaN   \n",
       "...              ...           ...  ...            ...            ...   \n",
       "11547   1.486836e+10           NaN  ...    179565695.0    179552815.0   \n",
       "11548            NaN           NaN  ...    179575936.0    179565695.0   \n",
       "11549            NaN           NaN  ...    179593285.0    179575936.0   \n",
       "11550            NaN           NaN  ...    179602579.0    179593285.0   \n",
       "11551            NaN           NaN  ...    179630514.0    179602579.0   \n",
       "\n",
       "       utxo_count_16  utxo_count_17  utxo_count_18  utxo_count_19  \\\n",
       "0                NaN            NaN            NaN            NaN   \n",
       "1                NaN            NaN            NaN            NaN   \n",
       "2                NaN            NaN            NaN            NaN   \n",
       "3                NaN            NaN            NaN            NaN   \n",
       "4                NaN            NaN            NaN            NaN   \n",
       "...              ...            ...            ...            ...   \n",
       "11547    179543052.0    179504816.0    179479822.0    179474550.0   \n",
       "11548    179552815.0    179543052.0    179504816.0    179479822.0   \n",
       "11549    179565695.0    179552815.0    179543052.0    179504816.0   \n",
       "11550    179575936.0    179565695.0    179552815.0    179543052.0   \n",
       "11551    179593285.0    179575936.0    179565695.0    179552815.0   \n",
       "\n",
       "       utxo_count_20  utxo_count_21  utxo_count_22  utxo_count_23  \n",
       "0                NaN            NaN            NaN            NaN  \n",
       "1                NaN            NaN            NaN            NaN  \n",
       "2                NaN            NaN            NaN            NaN  \n",
       "3                NaN            NaN            NaN            NaN  \n",
       "4                NaN            NaN            NaN            NaN  \n",
       "...              ...            ...            ...            ...  \n",
       "11547    179469208.0    179467442.0    179463219.0    179459713.0  \n",
       "11548    179474550.0    179469208.0    179467442.0    179463219.0  \n",
       "11549    179479822.0    179474550.0    179469208.0    179467442.0  \n",
       "11550    179504816.0    179479822.0    179474550.0    179469208.0  \n",
       "11551    179543052.0    179504816.0    179479822.0    179474550.0  \n",
       "\n",
       "[11552 rows x 158 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _type에 따라 train, test 분리\n",
    "train_df = df.loc[df[\"_type\"]==\"train\"].drop(columns=[\"_type\"])\n",
    "test_df = df.loc[df[\"_type\"]==\"test\"].drop(columns=[\"_type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost 라이브러리에 구현되어 있는 XGBRegressor 모델을 사용하여 학습 및 평가를 진행합니다. xgboost의 래퍼 클래스(wrapper class) 중 **사이킷런 래퍼**를 사용할 예정입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model parameter (XGBRegressor)\n",
    "* n_estimator: 트리의 개수 (디폴트 = 100)  \n",
    "\n",
    "* learning_rate: 학습 단계별 가중치를 얼마나 사용할지(이전 결과를 얼마나 반영할 것인지) 결정. 일반적으로 0.01 ~ 0.2\n",
    "\n",
    "* max_depth: 트리의 최대 깊이. (디폴트 = 6) 일반적으로 3 ~ 10  \n",
    "\n",
    "* min_child_weight: child에서 필요한 모든 관측치에 대한 가중치의 최소 합. 이 값보다 샘플 수가 작으면 leaf node가 된다. 너무 큰 값을 적용하면 과소적합이 될 수 있다.  \n",
    "\n",
    "* early stopping_rounds: 최대한 몇 개의 트리를 완성해볼 것인지 결정. valid loss에 더 이상 진전이 없으면 멈춘다. n_estimator가 높을 때 주로 사용  \n",
    "\n",
    "* gamma: 트리에서 추가적으로 가지를 나눌지를 결정할 최소 손실 감소값. 값이 클수록 과적합 감소 효과  \n",
    "\n",
    "* subsample: 각 트리마다 데이터 샘플링 비율. (디폴트 = 1) 일반적으로 0.5 ~ 1  \n",
    "\n",
    "* colsample_bytree: 각 트리마다 feature 샘플링 비율. (디폴트 = 1) 일반적으로 0.5 ~ 1  \n",
    "\n",
    "* reg_lambda: L2 regularization 가중치 (디폴트 = 1)  \n",
    "\n",
    "* reg_alpha: L1 regularization 가중치 (디폴트 = 1)  \n",
    "\n",
    "* scale_pos_weight: 데이터가 불균형할때 사용, 0보다 큰 값. (디폴트 = 1) 보통 값을 (음성 데이터 수)/(양성 데이터 수) 값으로 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fit 파라미터\n",
    "\n",
    "* early_stopping_rounds:\n",
    "* eval_metric: \n",
    "* eval_set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop([\"ID\", \"target\", \"close\"], axis=1)\n",
    "y_train = train_df[\"close\"]\n",
    "target = train_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_to_class(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"close 변수를 target값으로 변환하는 함수입니다.\n",
    "\n",
    "    Args:\n",
    "        series (pd.Series): 변환을 원하는 close 변수\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: 변환된 target 값\n",
    "    \"\"\"\n",
    "    close = pd.DataFrame()\n",
    "    close['close'] = series\n",
    "    close['close_lag1'] = close['close'].shift(1)\n",
    "    close['close_lag1_percent'] = (close['close'] - close['close_lag1']) / close['close_lag1']\n",
    "    close['class'] = close['close']\n",
    "    for i in range(close.shape[0]):\n",
    "        if close.loc[i, 'close_lag1_percent'] < -0.005:\n",
    "            close.loc[i, 'class'] = 0\n",
    "        elif close.loc[i, 'close_lag1_percent'] < 0:\n",
    "            close.loc[i, 'class'] = 1\n",
    "        elif close.loc[i, 'close_lag1_percent'] < 0.005:\n",
    "            close.loc[i, 'class'] = 2\n",
    "        else:\n",
    "            close.loc[i, 'class'] = 3\n",
    "            \n",
    "    return close[\"class\"].shift(-1).fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "def evaluate(valid_target: pd.Series, \n",
    "             y_valid: pd.Series, \n",
    "             y_pred: np.ndarray, \n",
    "             metric: str\n",
    ") -> float:\n",
    "    \"\"\"평가지표를 반환하는 함수입니다.\n",
    "\n",
    "    Args:\n",
    "        X_valid (pd.DataFrame): \n",
    "        y_valid (pd.Series): \n",
    "        y_pred (np.ndarray): 모델을 사용하여 예측한 변수\n",
    "        metric (str): 사용할 평가지표 metric 이름\n",
    "\n",
    "    Returns:\n",
    "        float: 사용할 평가지표 metric 값\n",
    "    \"\"\"\n",
    "    if metric == \"accuracy\":\n",
    "        classes = close_to_class(y_pred)\n",
    "        return accuracy_score(valid_target, classes)\n",
    "    elif metric == \"mae\":\n",
    "        return mean_absolute_error(y_valid, y_pred)\n",
    "    elif metric == \"mse\":\n",
    "        return mean_squared_error(y_valid, y_pred)\n",
    "    elif metric == \"mape\":\n",
    "        return mean_absolute_percentage_error(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model: Any, \n",
    "                X_train: pd.DataFrame, \n",
    "                y_train: pd.Series, \n",
    "                cv: int, \n",
    "                metric: str, \n",
    ") -> float:\n",
    "    \"\"\"K-Fold로 데이터를 분할한 후 전처리를 거쳐 주어진 모델로 데이터를 학습 및 평가를 진행합니다.\n",
    "\n",
    "    Args:\n",
    "        model (Any): 사용하는 모델 객체\n",
    "        X_train (pd.DataFrame): 설명변수로 이루어진 학습 데이터프레임\n",
    "        y_train (pd.Seris): 예측변수로 이루어진 학습 시리즈\n",
    "        cv (int): 교차검증시 분할할 폴드의 수\n",
    "        metric (str): 사용할 평가지표 metric 이름\n",
    "\n",
    "    Returns:\n",
    "        Any, float: \n",
    "    \"\"\"\n",
    "    kfold = KFold(n_splits=cv)\n",
    "    # kfold = KFold(n_splits=cv, shuffle=True, random_state=42)  # shuffle 켰을 때\n",
    "    score_list = []\n",
    "    \n",
    "    # warm_start는 모델의 속성으로, 같은 모델을 반복 학습할 때 이전 학습에서 학습된 파라미터를 초기화하지 않고 이어서 학습을 진행하는 옵션\n",
    "    if hasattr(model, \"warm_start\"):\n",
    "        model.warm_start = True\n",
    "\n",
    "    # K-Fold 교차 검증\n",
    "    for train_index, valid_index in kfold.split(X_train):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_valid, y_valid = X_train.iloc[valid_index], y_train.iloc[valid_index]\n",
    "\n",
    "        valid_target = target[valid_index]\n",
    "        \n",
    "        # 전처리\n",
    "        X_train_fold.fillna(X_train_fold.mean(), inplace=True)\n",
    "        y_train_fold.fillna(y_train_fold.mean(), inplace=True)\n",
    "        X_valid.fillna(X_valid.mean(), inplace=True)\n",
    "        y_valid.fillna(y_valid.mean(), inplace=True)  # 이 부분을 mice와 같은 방법으로 조정할 예정. feature selection 등도 여기에서.\n",
    "\n",
    "        \n",
    "        # 모델 학습\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        y_pred = model.predict(X_valid)\n",
    "        score = evaluate(valid_target, y_valid, y_pred, metric=metric)  # 평가지표 metric 반환\n",
    "        score_list.append(score)\n",
    "    \n",
    "    return np.mean(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1e-1),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 9),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 5),\n",
    "        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.3, 1.0),\n",
    "        \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
    "        \"device\": \"gpu\",\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "    \n",
    "    xgb_model = XGBRegressor(**params)\n",
    "    acc = model_train(xgb_model, X_train, y_train, cv=5, metric=\"accuracy\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-24 10:21:20,426] A new study created in memory with name: no-name-708b6366-4b58-4a4e-a44a-d58dbe142c32\n",
      "[I 2024-09-24 10:21:26,220] Trial 0 finished with value: 0.5069634703196347 and parameters: {'n_estimators': 216, 'learning_rate': 0.019387246842066348, 'max_depth': 6, 'min_child_weight': 5, 'colsample_bytree': 0.5738646088603621, 'subsample': 0.9602903524450304}. Best is trial 0 with value: 0.5069634703196347.\n",
      "[I 2024-09-24 10:21:29,597] Trial 1 finished with value: 0.39965753424657535 and parameters: {'n_estimators': 61, 'learning_rate': 0.0112325564068672, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.6854465459192668, 'subsample': 0.9992419036931234}. Best is trial 0 with value: 0.5069634703196347.\n",
      "[I 2024-09-24 10:21:34,156] Trial 2 finished with value: 0.43698630136986305 and parameters: {'n_estimators': 91, 'learning_rate': 0.014633219840434308, 'max_depth': 9, 'min_child_weight': 2, 'colsample_bytree': 0.4103065993068127, 'subsample': 0.663107382933317}. Best is trial 0 with value: 0.5069634703196347.\n",
      "[I 2024-09-24 10:21:38,144] Trial 3 finished with value: 0.4849315068493151 and parameters: {'n_estimators': 132, 'learning_rate': 0.026932092336316073, 'max_depth': 4, 'min_child_weight': 4, 'colsample_bytree': 0.7207227806391807, 'subsample': 0.8496825736987708}. Best is trial 0 with value: 0.5069634703196347.\n",
      "[I 2024-09-24 10:21:43,955] Trial 4 finished with value: 0.4319634703196347 and parameters: {'n_estimators': 198, 'learning_rate': 0.006421909830790599, 'max_depth': 7, 'min_child_weight': 1, 'colsample_bytree': 0.3578258230956935, 'subsample': 0.9027808783724074}. Best is trial 0 with value: 0.5069634703196347.\n",
      "[I 2024-09-24 10:21:48,393] Trial 5 finished with value: 0.4026255707762557 and parameters: {'n_estimators': 188, 'learning_rate': 0.001637792611683688, 'max_depth': 4, 'min_child_weight': 3, 'colsample_bytree': 0.7786794631917935, 'subsample': 0.8313949822173505}. Best is trial 0 with value: 0.5069634703196347.\n",
      "[I 2024-09-24 10:21:51,883] Trial 6 finished with value: 0.4066210045662101 and parameters: {'n_estimators': 81, 'learning_rate': 0.0016350479596271034, 'max_depth': 4, 'min_child_weight': 3, 'colsample_bytree': 0.5314261081086171, 'subsample': 0.6393418030239969}. Best is trial 0 with value: 0.5069634703196347.\n",
      "[I 2024-09-24 10:21:58,254] Trial 7 finished with value: 0.4574200913242009 and parameters: {'n_estimators': 236, 'learning_rate': 0.007384962429695001, 'max_depth': 7, 'min_child_weight': 5, 'colsample_bytree': 0.8947751207728838, 'subsample': 0.8122075489237673}. Best is trial 0 with value: 0.5069634703196347.\n",
      "[I 2024-09-24 10:22:02,970] Trial 8 finished with value: 0.40719178082191787 and parameters: {'n_estimators': 274, 'learning_rate': 0.0014299030930605982, 'max_depth': 3, 'min_child_weight': 3, 'colsample_bytree': 0.8225634280713161, 'subsample': 0.8168044689976537}. Best is trial 0 with value: 0.5069634703196347.\n",
      "[I 2024-09-24 10:22:09,598] Trial 9 finished with value: 0.49897260273972605 and parameters: {'n_estimators': 265, 'learning_rate': 0.03944315902757008, 'max_depth': 7, 'min_child_weight': 5, 'colsample_bytree': 0.44282306831965434, 'subsample': 0.9690709030387841}. Best is trial 0 with value: 0.5069634703196347.\n",
      "[I 2024-09-24 10:22:15,081] Trial 10 finished with value: 0.48584474885844753 and parameters: {'n_estimators': 143, 'learning_rate': 0.09704843933477884, 'max_depth': 9, 'min_child_weight': 4, 'colsample_bytree': 0.5517503527854452, 'subsample': 0.5249612558483729}. Best is trial 0 with value: 0.5069634703196347.\n",
      "[I 2024-09-24 10:22:21,103] Trial 11 finished with value: 0.47853881278538823 and parameters: {'n_estimators': 277, 'learning_rate': 0.04916922341734921, 'max_depth': 6, 'min_child_weight': 5, 'colsample_bytree': 0.5043321824466235, 'subsample': 0.9919596720262703}. Best is trial 0 with value: 0.5069634703196347.\n",
      "[I 2024-09-24 10:22:26,686] Trial 12 finished with value: 0.5071917808219178 and parameters: {'n_estimators': 225, 'learning_rate': 0.031788122473629506, 'max_depth': 6, 'min_child_weight': 5, 'colsample_bytree': 0.6013553712421219, 'subsample': 0.9194629947864374}. Best is trial 12 with value: 0.5071917808219178.\n",
      "[I 2024-09-24 10:22:32,367] Trial 13 finished with value: 0.5082191780821917 and parameters: {'n_estimators': 225, 'learning_rate': 0.02294746287218473, 'max_depth': 6, 'min_child_weight': 4, 'colsample_bytree': 0.6158899237802289, 'subsample': 0.9209233189610843}. Best is trial 13 with value: 0.5082191780821917.\n",
      "[I 2024-09-24 10:22:37,440] Trial 14 finished with value: 0.48162100456621004 and parameters: {'n_estimators': 239, 'learning_rate': 0.07278423961286487, 'max_depth': 5, 'min_child_weight': 4, 'colsample_bytree': 0.6477624680390078, 'subsample': 0.7449611722842018}. Best is trial 13 with value: 0.5082191780821917.\n",
      "[I 2024-09-24 10:22:42,841] Trial 15 finished with value: 0.4255707762557078 and parameters: {'n_estimators': 154, 'learning_rate': 0.005031881456172215, 'max_depth': 8, 'min_child_weight': 4, 'colsample_bytree': 0.6187098021477628, 'subsample': 0.9132009235720102}. Best is trial 13 with value: 0.5082191780821917.\n",
      "[I 2024-09-24 10:22:48,075] Trial 16 finished with value: 0.5447488584474887 and parameters: {'n_estimators': 235, 'learning_rate': 0.02873286277302185, 'max_depth': 5, 'min_child_weight': 4, 'colsample_bytree': 0.9905933453282367, 'subsample': 0.7371079177620046}. Best is trial 16 with value: 0.5447488584474887.\n",
      "[I 2024-09-24 10:22:52,745] Trial 17 finished with value: 0.5081050228310502 and parameters: {'n_estimators': 179, 'learning_rate': 0.02187243120551523, 'max_depth': 5, 'min_child_weight': 2, 'colsample_bytree': 0.9931797102934012, 'subsample': 0.7012758737088545}. Best is trial 16 with value: 0.5447488584474887.\n",
      "[I 2024-09-24 10:22:58,611] Trial 18 finished with value: 0.3843607305936073 and parameters: {'n_estimators': 297, 'learning_rate': 0.003658797446402904, 'max_depth': 5, 'min_child_weight': 3, 'colsample_bytree': 0.9744036060076596, 'subsample': 0.5968924442669856}. Best is trial 16 with value: 0.5447488584474887.\n",
      "[I 2024-09-24 10:23:03,039] Trial 19 finished with value: 0.5126712328767123 and parameters: {'n_estimators': 249, 'learning_rate': 0.0566886196247315, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.8721504674251532, 'subsample': 0.7738915007856215}. Best is trial 16 with value: 0.5447488584474887.\n",
      "[I 2024-09-24 10:23:07,443] Trial 20 finished with value: 0.4831050228310502 and parameters: {'n_estimators': 251, 'learning_rate': 0.060295885608425207, 'max_depth': 3, 'min_child_weight': 2, 'colsample_bytree': 0.9018612562801157, 'subsample': 0.7585743506217092}. Best is trial 16 with value: 0.5447488584474887.\n",
      "[I 2024-09-24 10:23:11,597] Trial 21 finished with value: 0.5406392694063926 and parameters: {'n_estimators': 208, 'learning_rate': 0.04011087607240736, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.9024778374844874, 'subsample': 0.7524056559416976}. Best is trial 16 with value: 0.5447488584474887.\n",
      "[I 2024-09-24 10:23:15,684] Trial 22 finished with value: 0.5358447488584475 and parameters: {'n_estimators': 197, 'learning_rate': 0.04195726987301569, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.8946906922527315, 'subsample': 0.7599287082810374}. Best is trial 16 with value: 0.5447488584474887.\n",
      "[I 2024-09-24 10:23:19,833] Trial 23 finished with value: 0.5455479452054794 and parameters: {'n_estimators': 205, 'learning_rate': 0.037735944056280606, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.9412834626608442, 'subsample': 0.7120178113254312}. Best is trial 23 with value: 0.5455479452054794.\n",
      "[I 2024-09-24 10:23:23,943] Trial 24 finished with value: 0.39452054794520547 and parameters: {'n_estimators': 159, 'learning_rate': 0.014972942888036713, 'max_depth': 4, 'min_child_weight': 4, 'colsample_bytree': 0.9584757458481132, 'subsample': 0.7006603452092266}. Best is trial 23 with value: 0.5455479452054794.\n",
      "[I 2024-09-24 10:23:28,884] Trial 25 finished with value: 0.5438356164383562 and parameters: {'n_estimators': 203, 'learning_rate': 0.03331241225107139, 'max_depth': 5, 'min_child_weight': 3, 'colsample_bytree': 0.7921562392753656, 'subsample': 0.7082441390117783}. Best is trial 23 with value: 0.5455479452054794.\n",
      "[I 2024-09-24 10:23:33,466] Trial 26 finished with value: 0.5358447488584475 and parameters: {'n_estimators': 177, 'learning_rate': 0.03187181019776591, 'max_depth': 5, 'min_child_weight': 3, 'colsample_bytree': 0.7689710897590852, 'subsample': 0.6047285653760208}. Best is trial 23 with value: 0.5455479452054794.\n",
      "[I 2024-09-24 10:23:37,619] Trial 27 finished with value: 0.43162100456621005 and parameters: {'n_estimators': 122, 'learning_rate': 0.01588628418211242, 'max_depth': 5, 'min_child_weight': 3, 'colsample_bytree': 0.8511092256511599, 'subsample': 0.6930053828879759}. Best is trial 23 with value: 0.5455479452054794.\n",
      "[I 2024-09-24 10:23:42,430] Trial 28 finished with value: 0.5122146118721462 and parameters: {'n_estimators': 209, 'learning_rate': 0.07510458642745772, 'max_depth': 5, 'min_child_weight': 2, 'colsample_bytree': 0.8120240124944046, 'subsample': 0.5516559176463909}. Best is trial 23 with value: 0.5455479452054794.\n",
      "[I 2024-09-24 10:23:48,035] Trial 29 finished with value: 0.45479452054794517 and parameters: {'n_estimators': 164, 'learning_rate': 0.009797804730003402, 'max_depth': 8, 'min_child_weight': 3, 'colsample_bytree': 0.941346508368127, 'subsample': 0.6578807268049025}. Best is trial 23 with value: 0.5455479452054794.\n",
      "[I 2024-09-24 10:23:52,575] Trial 30 finished with value: 0.5244292237442922 and parameters: {'n_estimators': 216, 'learning_rate': 0.019600431394856024, 'max_depth': 4, 'min_child_weight': 5, 'colsample_bytree': 0.7528884249388561, 'subsample': 0.612021596070882}. Best is trial 23 with value: 0.5455479452054794.\n",
      "[I 2024-09-24 10:23:56,724] Trial 31 finished with value: 0.55 and parameters: {'n_estimators': 206, 'learning_rate': 0.03385294197740459, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.9166009969784618, 'subsample': 0.7151015814708105}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:24:00,803] Trial 32 finished with value: 0.5363013698630137 and parameters: {'n_estimators': 196, 'learning_rate': 0.03052076284639187, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.9360373863098068, 'subsample': 0.7146093226745905}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:24:05,336] Trial 33 finished with value: 0.4848173515981736 and parameters: {'n_estimators': 225, 'learning_rate': 0.09903361663944996, 'max_depth': 4, 'min_child_weight': 4, 'colsample_bytree': 0.8367025242113701, 'subsample': 0.720411690137771}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:24:10,155] Trial 34 finished with value: 0.5366438356164382 and parameters: {'n_estimators': 254, 'learning_rate': 0.026592700308125553, 'max_depth': 4, 'min_child_weight': 3, 'colsample_bytree': 0.9858526401147062, 'subsample': 0.785637012009064}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:24:15,900] Trial 35 finished with value: 0.49486301369863017 and parameters: {'n_estimators': 237, 'learning_rate': 0.009508024260174547, 'max_depth': 6, 'min_child_weight': 5, 'colsample_bytree': 0.6895603285401402, 'subsample': 0.6689574667550289}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:24:19,791] Trial 36 finished with value: 0.3844748858447488 and parameters: {'n_estimators': 117, 'learning_rate': 0.01370186648464277, 'max_depth': 4, 'min_child_weight': 2, 'colsample_bytree': 0.9338778256710684, 'subsample': 0.8779980514480079}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:24:23,780] Trial 37 finished with value: 0.5240867579908676 and parameters: {'n_estimators': 184, 'learning_rate': 0.048656285886853806, 'max_depth': 3, 'min_child_weight': 3, 'colsample_bytree': 0.7219337616773106, 'subsample': 0.7323147347808106}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:24:28,253] Trial 38 finished with value: 0.49372146118721466 and parameters: {'n_estimators': 203, 'learning_rate': 0.01805625905263673, 'max_depth': 4, 'min_child_weight': 3, 'colsample_bytree': 0.8570384503071201, 'subsample': 0.6752611707756416}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:24:32,799] Trial 39 finished with value: 0.41735159817351597 and parameters: {'n_estimators': 168, 'learning_rate': 0.011725989225162964, 'max_depth': 5, 'min_child_weight': 1, 'colsample_bytree': 0.996481750835659, 'subsample': 0.6370391316258184}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:24:36,539] Trial 40 finished with value: 0.3990867579908676 and parameters: {'n_estimators': 58, 'learning_rate': 0.0026619126311376007, 'max_depth': 7, 'min_child_weight': 4, 'colsample_bytree': 0.7867875951792018, 'subsample': 0.7841342858326785}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:24:40,719] Trial 41 finished with value: 0.5494292237442922 and parameters: {'n_estimators': 213, 'learning_rate': 0.03810847002505454, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.9022931777725132, 'subsample': 0.745653037452571}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:24:44,760] Trial 42 finished with value: 0.5371004566210045 and parameters: {'n_estimators': 188, 'learning_rate': 0.037529905464039094, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.9240319436249348, 'subsample': 0.8032452157085656}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:24:49,105] Trial 43 finished with value: 0.5205479452054795 and parameters: {'n_estimators': 215, 'learning_rate': 0.02560030987468579, 'max_depth': 3, 'min_child_weight': 5, 'colsample_bytree': 0.886878016155759, 'subsample': 0.8571902184490546}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:24:53,639] Trial 44 finished with value: 0.489041095890411 and parameters: {'n_estimators': 226, 'learning_rate': 0.07307533765749197, 'max_depth': 4, 'min_child_weight': 4, 'colsample_bytree': 0.9612891563284894, 'subsample': 0.7324892372761552}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:24:57,712] Trial 45 finished with value: 0.5308219178082192 and parameters: {'n_estimators': 193, 'learning_rate': 0.032501292036093477, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.8008795892315852, 'subsample': 0.6847121123541985}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:25:02,551] Trial 46 finished with value: 0.5054794520547945 and parameters: {'n_estimators': 265, 'learning_rate': 0.05399806714467245, 'max_depth': 4, 'min_child_weight': 5, 'colsample_bytree': 0.3221113582481565, 'subsample': 0.6545039263834853}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:25:08,363] Trial 47 finished with value: 0.5075342465753424 and parameters: {'n_estimators': 238, 'learning_rate': 0.02308106473812431, 'max_depth': 6, 'min_child_weight': 3, 'colsample_bytree': 0.9187168203932137, 'subsample': 0.8385093686359384}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:25:12,565] Trial 48 finished with value: 0.5343607305936072 and parameters: {'n_estimators': 216, 'learning_rate': 0.04580447638477542, 'max_depth': 3, 'min_child_weight': 3, 'colsample_bytree': 0.8293407165029035, 'subsample': 0.7156042173679775}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:25:16,538] Trial 49 finished with value: 0.5124429223744292 and parameters: {'n_estimators': 149, 'learning_rate': 0.06468938090078795, 'max_depth': 4, 'min_child_weight': 4, 'colsample_bytree': 0.7457783515802818, 'subsample': 0.8089918767151032}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:25:20,175] Trial 50 finished with value: 0.4012557077625571 and parameters: {'n_estimators': 77, 'learning_rate': 0.001070658537011886, 'max_depth': 5, 'min_child_weight': 4, 'colsample_bytree': 0.9592944134846423, 'subsample': 0.6217532344430512}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:25:24,385] Trial 51 finished with value: 0.5460045662100457 and parameters: {'n_estimators': 207, 'learning_rate': 0.038452211745162064, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.869217647432389, 'subsample': 0.7477847082102848}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:25:28,767] Trial 52 finished with value: 0.5465753424657535 and parameters: {'n_estimators': 227, 'learning_rate': 0.03599047955829037, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.8601836494352415, 'subsample': 0.7711730458577695}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:25:33,110] Trial 53 finished with value: 0.5486301369863014 and parameters: {'n_estimators': 231, 'learning_rate': 0.037527759234241155, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.8616839015874329, 'subsample': 0.738889757587531}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:25:37,371] Trial 54 finished with value: 0.544406392694064 and parameters: {'n_estimators': 226, 'learning_rate': 0.03876080070340314, 'max_depth': 3, 'min_child_weight': 5, 'colsample_bytree': 0.8613830569498039, 'subsample': 0.767764822381925}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:25:41,692] Trial 55 finished with value: 0.4940639269406392 and parameters: {'n_estimators': 244, 'learning_rate': 0.08174854810038958, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.8739940767390805, 'subsample': 0.7910597733599951}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:25:46,181] Trial 56 finished with value: 0.5277397260273973 and parameters: {'n_estimators': 262, 'learning_rate': 0.048800643002332895, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.4541659438243723, 'subsample': 0.7474104123749601}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:25:50,434] Trial 57 finished with value: 0.4841324200913242 and parameters: {'n_estimators': 218, 'learning_rate': 0.021007625540418334, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.912584600860201, 'subsample': 0.8250439788330293}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:25:54,387] Trial 58 finished with value: 0.5299086757990867 and parameters: {'n_estimators': 170, 'learning_rate': 0.035867102198099556, 'max_depth': 3, 'min_child_weight': 5, 'colsample_bytree': 0.8849781123683935, 'subsample': 0.7702476535385535}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:25:59,138] Trial 59 finished with value: 0.517351598173516 and parameters: {'n_estimators': 286, 'learning_rate': 0.06003645921105831, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.8413923694474749, 'subsample': 0.7306707383230487}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:26:03,577] Trial 60 finished with value: 0.5357305936073059 and parameters: {'n_estimators': 230, 'learning_rate': 0.04360432374349735, 'max_depth': 3, 'min_child_weight': 5, 'colsample_bytree': 0.8169481941984008, 'subsample': 0.6877595001236989}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:26:08,155] Trial 61 finished with value: 0.5415525114155251 and parameters: {'n_estimators': 208, 'learning_rate': 0.025799782642607565, 'max_depth': 4, 'min_child_weight': 4, 'colsample_bytree': 0.9602572146365369, 'subsample': 0.7441598847608328}. Best is trial 31 with value: 0.55.\n",
      "[I 2024-09-24 10:26:12,602] Trial 62 finished with value: 0.5591324200913241 and parameters: {'n_estimators': 244, 'learning_rate': 0.0296933486834867, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.941461522774965, 'subsample': 0.7387715489392699}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:26:17,124] Trial 63 finished with value: 0.5425799086757991 and parameters: {'n_estimators': 254, 'learning_rate': 0.035664580383834486, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.9097886789325169, 'subsample': 0.7982142083056973}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:26:21,599] Trial 64 finished with value: 0.47785388127853884 and parameters: {'n_estimators': 244, 'learning_rate': 0.01743090239469991, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.8761350969411232, 'subsample': 0.7580012854448056}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:26:25,759] Trial 65 finished with value: 0.5219178082191781 and parameters: {'n_estimators': 203, 'learning_rate': 0.027946714285814956, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.9438767626461264, 'subsample': 0.723416373113546}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:26:29,747] Trial 66 finished with value: 0.5279680365296804 and parameters: {'n_estimators': 183, 'learning_rate': 0.05222181550611453, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.8949524475034939, 'subsample': 0.6970125937715236}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:26:34,392] Trial 67 finished with value: 0.5218036529680365 and parameters: {'n_estimators': 233, 'learning_rate': 0.04249797796526759, 'max_depth': 4, 'min_child_weight': 4, 'colsample_bytree': 0.97676824727761, 'subsample': 0.7108637969172461}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:26:42,409] Trial 68 finished with value: 0.5027397260273974 and parameters: {'n_estimators': 220, 'learning_rate': 0.02915206160615933, 'max_depth': 9, 'min_child_weight': 4, 'colsample_bytree': 0.848778395500956, 'subsample': 0.7748778247149055}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:26:47,400] Trial 69 finished with value: 0.5442922374429224 and parameters: {'n_estimators': 277, 'learning_rate': 0.02449852711035964, 'max_depth': 4, 'min_child_weight': 4, 'colsample_bytree': 0.9388444068000549, 'subsample': 0.746846968924259}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:26:51,465] Trial 70 finished with value: 0.49383561643835616 and parameters: {'n_estimators': 191, 'learning_rate': 0.08614796045513783, 'max_depth': 3, 'min_child_weight': 5, 'colsample_bytree': 0.7692976276655343, 'subsample': 0.5816936098168722}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:26:58,929] Trial 71 finished with value: 0.5139269406392695 and parameters: {'n_estimators': 244, 'learning_rate': 0.030193447174632477, 'max_depth': 8, 'min_child_weight': 4, 'colsample_bytree': 0.993574258119731, 'subsample': 0.7309561504196961}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:27:03,153] Trial 72 finished with value: 0.5030821917808219 and parameters: {'n_estimators': 210, 'learning_rate': 0.06564730343701784, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.9734514382088312, 'subsample': 0.7405066448693448}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:27:07,699] Trial 73 finished with value: 0.5405251141552512 and parameters: {'n_estimators': 257, 'learning_rate': 0.03593663122901273, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.921161313821563, 'subsample': 0.679021266933348}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:27:12,192] Trial 74 finished with value: 0.5143835616438356 and parameters: {'n_estimators': 199, 'learning_rate': 0.020963488549806703, 'max_depth': 4, 'min_child_weight': 4, 'colsample_bytree': 0.9033903141481249, 'subsample': 0.7032586347333821}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:27:16,520] Trial 75 finished with value: 0.5417808219178083 and parameters: {'n_estimators': 232, 'learning_rate': 0.04158991709257305, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.94860556497936, 'subsample': 0.7754226040247686}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:27:20,814] Trial 76 finished with value: 0.3845890410958904 and parameters: {'n_estimators': 221, 'learning_rate': 0.007300284118988682, 'max_depth': 3, 'min_child_weight': 3, 'colsample_bytree': 0.869638927270611, 'subsample': 0.7524098669180905}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:27:25,375] Trial 77 finished with value: 0.5490867579908676 and parameters: {'n_estimators': 271, 'learning_rate': 0.03242176404274697, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.5677901425268077, 'subsample': 0.6524053012635037}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:27:29,752] Trial 78 finished with value: 0.5215753424657534 and parameters: {'n_estimators': 246, 'learning_rate': 0.05443801424071968, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.5676778506116039, 'subsample': 0.6437070661775139}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:27:34,672] Trial 79 finished with value: 0.5350456621004567 and parameters: {'n_estimators': 274, 'learning_rate': 0.03310550415072052, 'max_depth': 4, 'min_child_weight': 4, 'colsample_bytree': 0.6266199603391736, 'subsample': 0.6644525800364649}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:27:38,874] Trial 80 finished with value: 0.5321917808219178 and parameters: {'n_estimators': 210, 'learning_rate': 0.04686698298295655, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.5259423527943944, 'subsample': 0.5789673097653762}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:27:43,618] Trial 81 finished with value: 0.5480593607305936 and parameters: {'n_estimators': 296, 'learning_rate': 0.027677375272974765, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.6503358381862251, 'subsample': 0.7591895743094308}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:27:48,403] Trial 82 finished with value: 0.5541095890410959 and parameters: {'n_estimators': 293, 'learning_rate': 0.027859061757211694, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.6795322080967284, 'subsample': 0.7197407665753084}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:27:53,203] Trial 83 finished with value: 0.5562785388127854 and parameters: {'n_estimators': 299, 'learning_rate': 0.02415096493903567, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.6224915075947021, 'subsample': 0.7588732273530748}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:27:57,998] Trial 84 finished with value: 0.5175799086757991 and parameters: {'n_estimators': 297, 'learning_rate': 0.018426719693714386, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.6550500488047375, 'subsample': 0.8177711918452962}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:28:02,678] Trial 85 finished with value: 0.45650684931506846 and parameters: {'n_estimators': 285, 'learning_rate': 0.012855117089637116, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.5953842124519938, 'subsample': 0.7901539061283205}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:28:07,864] Trial 86 finished with value: 0.5503424657534246 and parameters: {'n_estimators': 290, 'learning_rate': 0.022895516534710773, 'max_depth': 4, 'min_child_weight': 4, 'colsample_bytree': 0.661713770383479, 'subsample': 0.7649372360820187}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:28:13,000] Trial 87 finished with value: 0.5505707762557078 and parameters: {'n_estimators': 288, 'learning_rate': 0.022859139374226387, 'max_depth': 4, 'min_child_weight': 3, 'colsample_bytree': 0.670588294399677, 'subsample': 0.7610302920356186}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:28:18,137] Trial 88 finished with value: 0.5318493150684931 and parameters: {'n_estimators': 287, 'learning_rate': 0.01585993436485779, 'max_depth': 4, 'min_child_weight': 3, 'colsample_bytree': 0.6848789622999949, 'subsample': 0.7228532076327356}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:28:23,256] Trial 89 finished with value: 0.5407534246575343 and parameters: {'n_estimators': 291, 'learning_rate': 0.024050672655656306, 'max_depth': 4, 'min_child_weight': 3, 'colsample_bytree': 0.6714029239086516, 'subsample': 0.7832124311460846}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:28:28,336] Trial 90 finished with value: 0.5474885844748859 and parameters: {'n_estimators': 272, 'learning_rate': 0.01995657369035392, 'max_depth': 4, 'min_child_weight': 3, 'colsample_bytree': 0.590570644874942, 'subsample': 0.691531832531711}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:28:33,095] Trial 91 finished with value: 0.5471461187214612 and parameters: {'n_estimators': 299, 'learning_rate': 0.028890717375070468, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.6362327766662326, 'subsample': 0.7644899532215763}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:28:37,702] Trial 92 finished with value: 0.5480593607305936 and parameters: {'n_estimators': 280, 'learning_rate': 0.022752539992273738, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.7115512796368357, 'subsample': 0.7602619768747764}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:28:42,389] Trial 93 finished with value: 0.5476027397260274 and parameters: {'n_estimators': 293, 'learning_rate': 0.025749416809816714, 'max_depth': 3, 'min_child_weight': 3, 'colsample_bytree': 0.5533365696346741, 'subsample': 0.7360532950400426}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:28:46,966] Trial 94 finished with value: 0.5029680365296804 and parameters: {'n_estimators': 265, 'learning_rate': 0.01728331358584235, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.6659222729864781, 'subsample': 0.7171877757071167}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:28:51,977] Trial 95 finished with value: 0.5373287671232877 and parameters: {'n_estimators': 282, 'learning_rate': 0.030734541730365585, 'max_depth': 4, 'min_child_weight': 3, 'colsample_bytree': 0.49800163312595025, 'subsample': 0.7944868195038084}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:28:56,566] Trial 96 finished with value: 0.5208904109589041 and parameters: {'n_estimators': 270, 'learning_rate': 0.022240073175901133, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.6171597399018206, 'subsample': 0.9573804082816305}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:29:01,335] Trial 97 finished with value: 0.5405251141552512 and parameters: {'n_estimators': 291, 'learning_rate': 0.027522035887371493, 'max_depth': 3, 'min_child_weight': 1, 'colsample_bytree': 0.7032509843715069, 'subsample': 0.7065759575184671}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:29:06,448] Trial 98 finished with value: 0.5308219178082192 and parameters: {'n_estimators': 291, 'learning_rate': 0.033541207361671814, 'max_depth': 4, 'min_child_weight': 4, 'colsample_bytree': 0.7381316033498695, 'subsample': 0.8048300974435495}. Best is trial 62 with value: 0.5591324200913241.\n",
      "[I 2024-09-24 10:29:11,365] Trial 99 finished with value: 0.38481735159817354 and parameters: {'n_estimators': 300, 'learning_rate': 0.004971966539571849, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.6369217530699484, 'subsample': 0.5212005962155916}. Best is trial 62 with value: 0.5591324200913241.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'n_estimators': 244, 'learning_rate': 0.0296933486834867, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.941461522774965, 'subsample': 0.7387715489392699}\n",
      "XGBoost model accuracy: 0.5591324200913241\n"
     ]
    }
   ],
   "source": [
    "# Optuna study 생성 및 최적화 실행\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"Best Hyperparameters: \", study.best_params)\n",
    "\n",
    "# 최적의 하이퍼파라미터를 사용하여 최종 모델 생성\n",
    "best_params = study.best_params\n",
    "best_params[\"device\"] = \"gpu\"\n",
    "best_params[\"random_state\"] = 42\n",
    "best_xgb_model = XGBRegressor(**best_params)\n",
    "\n",
    "# 최종 모델 평가\n",
    "acc = model_train(best_xgb_model, X_train, y_train, cv=5, metric=\"accuracy\")\n",
    "print(f\"XGBoost model accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop([\"ID\", \"target\", \"close\"], axis=1)\n",
    "X_test.fillna(X_test.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_xgb_model.predict(X_test)\n",
    "y_test_pred_class = close_to_class(y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output File Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output file 할당후 save \n",
    "submission_df = submission_df.assign(target = y_test_pred_class)\n",
    "submission_df[\"target\"] = submission_df[\"target\"].astype(np.int8)\n",
    "submission_df.to_csv(\"output.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-lecture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
