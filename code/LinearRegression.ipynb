{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 호출\n",
    "data_path: str = \"/data/ephemeral/home/BTC/data\"\n",
    "train_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"train.csv\")).assign(_type=\"train\") # train 에는 _type = train \n",
    "test_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"test.csv\")).assign(_type=\"test\") # test 에는 _type = test\n",
    "submission_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"test.csv\")) # ID, target 열만 가진 데이터 미리 호출\n",
    "df: pd.DataFrame = pd.concat([train_df, test_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:03<00:00, 28.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# HOURLY_ 로 시작하는 .csv 파일 이름을 file_names 에 할딩\n",
    "file_names: List[str] = [\n",
    "    f for f in os.listdir(data_path) if f.startswith(\"HOURLY_\") and f.endswith(\".csv\")\n",
    "]\n",
    "\n",
    "# 파일명 : 데이터프레임으로 딕셔너리 형태로 저장\n",
    "file_dict: Dict[str, pd.DataFrame] = {\n",
    "    f.replace(\".csv\", \"\"): pd.read_csv(os.path.join(data_path, f)) for f in file_names\n",
    "}\n",
    "\n",
    "for _file_name, _df in tqdm(file_dict.items()):\n",
    "    # 열 이름 중복 방지를 위해 {_file_name.lower()}_{col.lower()}로 변경, datetime 열을 ID로 변경\n",
    "    _rename_rule = {\n",
    "        col: f\"{_file_name.lower()}_{col.lower()}\" if col != \"datetime\" else \"ID\"\n",
    "        for col in _df.columns\n",
    "    }\n",
    "    _df = _df.rename(_rename_rule, axis=1)\n",
    "    df = df.merge(_df, on=\"ID\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA (Explanatory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:15: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11552, 43)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델에 사용할 컬럼, 컬럼의 rename rule을 미리 할당함\n",
    "cols_dict: Dict[str, str] = {\n",
    "    \"ID\": \"ID\",\n",
    "    \"target\": \"target\",\n",
    "    \"_type\": \"_type\",\n",
    "\n",
    "    \"hourly_market-data_funding-rates_all_exchange_funding_rates\": \"funding_rates\",\n",
    "\n",
    "    \"hourly_market-data_liquidations_all_exchange_all_symbol_long_liquidations\": \"long_liquidations\",\n",
    "    \"hourly_market-data_liquidations_all_exchange_all_symbol_short_liquidations\": \"short_liquidations\",\n",
    "    \"hourly_market-data_liquidations_all_exchange_all_symbol_long_liquidations_usd\": \"long_liquidations_usd\",\n",
    "    \"hourly_market-data_liquidations_all_exchange_all_symbol_short_liquidations_usd\": \"short_liquidations_usd\",\n",
    "    \n",
    "    \"hourly_market-data_open-interest_all_exchange_all_symbol_open_interest\": \"open_interest\",\n",
    "\n",
    "    \"hourly_market-data_price-ohlcv_all_exchange_spot_btc_usd_close\": \"close\",\n",
    "    \n",
    "    \"hourly_market-data_taker-buy-sell-stats_all_exchange_taker_buy_volume\": \"taker_buy_volume\",\n",
    "    \"hourly_market-data_taker-buy-sell-stats_all_exchange_taker_sell_volume\": \"taker_sell_volume\",\n",
    "    \"hourly_market-data_taker-buy-sell-stats_all_exchange_taker_buy_ratio\": \"taker_buy_ratio\",\n",
    "    \"hourly_market-data_taker-buy-sell-stats_all_exchange_taker_sell_ratio\": \"taker_sell_ratio\",\n",
    "    \"hourly_market-data_taker-buy-sell-stats_all_exchange_taker_buy_sell_ratio\": \"taker_buy_sell_ratio\",\n",
    "\n",
    "    \"hourly_network-data_addresses-count_addresses_count_active\": \"addresses_count_active\",\n",
    "    \"hourly_network-data_addresses-count_addresses_count_sender\": \"addresses_count_sender\",\n",
    "    \"hourly_network-data_addresses-count_addresses_count_receiver\": \"addresses_count_receiver\",\n",
    "\n",
    "    \"hourly_network-data_block-bytes_block_bytes\": \"block_bytes\",\n",
    "\n",
    "    \"hourly_network-data_block-count_block_count\": \"block_count\",\n",
    "    \n",
    "    \"hourly_network-data_block-interval_block_interval\": \"block_interval\",\n",
    "\n",
    "    \"hourly_network-data_blockreward_blockreward\": \"blockreward\",\n",
    "    \"hourly_network-data_blockreward_blockreward_usd\": \"blockreward_usd\",\n",
    "    \n",
    "    \"hourly_network-data_difficulty_difficulty\": \"difficulty\",\n",
    "\n",
    "    \"hourly_network-data_fees_fees_block_mean\": \"fees_block_mean\",\n",
    "    \"hourly_network-data_fees_fees_block_mean_usd\": \"fees_block_mean_usd\",\n",
    "    \"hourly_network-data_fees_fees_total\": \"fees_total\",\n",
    "    \"hourly_network-data_fees_fees_total_usd\": \"fees_total_usd\",\n",
    "    \"hourly_network-data_fees_fees_reward_percent\": \"fees_reward_percent\",\n",
    "\n",
    "    \"hourly_network-data_fees-transaction_fees_transaction_mean\": \"fees_transaction_mean\",\n",
    "    \"hourly_network-data_fees-transaction_fees_transaction_mean_usd\": \"fees_transaction_mean_usd\",\n",
    "    \"hourly_network-data_fees-transaction_fees_transaction_median\": \"fees_transaction_median\",\n",
    "    \"hourly_network-data_fees-transaction_fees_transaction_median_usd\": \"fees_transaction_median_usd\",\n",
    "\n",
    "    \"hourly_network-data_hashrate_hashrate\": \"hashrate\",\n",
    "\n",
    "    \"hourly_network-data_supply_supply_total\": \"supply_total\",\n",
    "    \"hourly_network-data_supply_supply_new\": \"supply_new\",\n",
    "\n",
    "    \"hourly_network-data_tokens-transferred_tokens_transferred_total\": \"tokens_transferred_total\",\n",
    "    \"hourly_network-data_tokens-transferred_tokens_transferred_mean\": \"tokens_transferred_mean\",\n",
    "    \"hourly_network-data_tokens-transferred_tokens_transferred_median\": \"tokens_transferred_median\",\n",
    "\n",
    "    \"hourly_network-data_transactions-count_transactions_count_total\": \"transactions_count_total\",\n",
    "    \"hourly_network-data_transactions-count_transactions_count_mean\": \"transactions_count_mean\",\n",
    "\n",
    "    \"hourly_network-data_utxo-count_utxo_count\": \"utxo_count\",\n",
    "    \n",
    "    \"hourly_network-data_velocity_velocity_supply_total\": \"velocity_supply_total\"\n",
    "}\n",
    "df = df[cols_dict.keys()].rename(cols_dict, axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continuous 열을 따로 할당해둠\n",
    "conti_cols: List[str] = [\n",
    "    \"close\",\n",
    "    \"open_interest\",\n",
    "    # \"difficulty\",\n",
    "    # \"supply_total\",\n",
    "    \"utxo_count\"\n",
    "]\n",
    "\n",
    "# 최대 24시간의 shift 피쳐를 계산\n",
    "shift_list = shift_feature(\n",
    "    df=df, conti_cols=conti_cols, intervals=[_ for _ in range(1, 6)]\n",
    ")\n",
    "\n",
    "# concat 하여 df 에 할당\n",
    "df = pd.concat([df, pd.concat(shift_list, axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>_type</th>\n",
       "      <th>funding_rates</th>\n",
       "      <th>long_liquidations</th>\n",
       "      <th>short_liquidations</th>\n",
       "      <th>long_liquidations_usd</th>\n",
       "      <th>short_liquidations_usd</th>\n",
       "      <th>open_interest</th>\n",
       "      <th>close</th>\n",
       "      <th>...</th>\n",
       "      <th>open_interest_1</th>\n",
       "      <th>open_interest_2</th>\n",
       "      <th>open_interest_3</th>\n",
       "      <th>open_interest_4</th>\n",
       "      <th>open_interest_5</th>\n",
       "      <th>utxo_count_1</th>\n",
       "      <th>utxo_count_2</th>\n",
       "      <th>utxo_count_3</th>\n",
       "      <th>utxo_count_4</th>\n",
       "      <th>utxo_count_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>197.51610</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.271344e+09</td>\n",
       "      <td>16536.747967</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11833.56104</td>\n",
       "      <td>6.288683e+09</td>\n",
       "      <td>16557.136536</td>\n",
       "      <td>...</td>\n",
       "      <td>6.271344e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83308092.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 02:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.286796e+09</td>\n",
       "      <td>16548.149805</td>\n",
       "      <td>...</td>\n",
       "      <td>6.288683e+09</td>\n",
       "      <td>6.271344e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83314883.0</td>\n",
       "      <td>83308092.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 03:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.005067</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9754.76891</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.284575e+09</td>\n",
       "      <td>16533.632875</td>\n",
       "      <td>...</td>\n",
       "      <td>6.286796e+09</td>\n",
       "      <td>6.288683e+09</td>\n",
       "      <td>6.271344e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83314090.0</td>\n",
       "      <td>83314883.0</td>\n",
       "      <td>83308092.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 04:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.006210</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5944.43714</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.291582e+09</td>\n",
       "      <td>16524.712159</td>\n",
       "      <td>...</td>\n",
       "      <td>6.284575e+09</td>\n",
       "      <td>6.286796e+09</td>\n",
       "      <td>6.288683e+09</td>\n",
       "      <td>6.271344e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83326258.0</td>\n",
       "      <td>83314090.0</td>\n",
       "      <td>83314883.0</td>\n",
       "      <td>83308092.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11547</th>\n",
       "      <td>2024-04-26 03:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.243500</td>\n",
       "      <td>45484.20433</td>\n",
       "      <td>15682.76464</td>\n",
       "      <td>1.486836e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489030e+10</td>\n",
       "      <td>1.481352e+10</td>\n",
       "      <td>1.475586e+10</td>\n",
       "      <td>1.477917e+10</td>\n",
       "      <td>1.478950e+10</td>\n",
       "      <td>179811932.0</td>\n",
       "      <td>179793126.0</td>\n",
       "      <td>179753959.0</td>\n",
       "      <td>179728506.0</td>\n",
       "      <td>179718697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11548</th>\n",
       "      <td>2024-04-26 04:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.577208</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>420718.03779</td>\n",
       "      <td>9419.65430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.486836e+10</td>\n",
       "      <td>1.489030e+10</td>\n",
       "      <td>1.481352e+10</td>\n",
       "      <td>1.475586e+10</td>\n",
       "      <td>1.477917e+10</td>\n",
       "      <td>179820708.0</td>\n",
       "      <td>179811932.0</td>\n",
       "      <td>179793126.0</td>\n",
       "      <td>179753959.0</td>\n",
       "      <td>179728506.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11549</th>\n",
       "      <td>2024-04-26 05:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.797163</td>\n",
       "      <td>5.216490</td>\n",
       "      <td>114902.59095</td>\n",
       "      <td>337367.12807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.486836e+10</td>\n",
       "      <td>1.489030e+10</td>\n",
       "      <td>1.481352e+10</td>\n",
       "      <td>1.475586e+10</td>\n",
       "      <td>179833897.0</td>\n",
       "      <td>179820708.0</td>\n",
       "      <td>179811932.0</td>\n",
       "      <td>179793126.0</td>\n",
       "      <td>179753959.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11550</th>\n",
       "      <td>2024-04-26 06:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.803000</td>\n",
       "      <td>1.656000</td>\n",
       "      <td>51434.51531</td>\n",
       "      <td>106931.54104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.486836e+10</td>\n",
       "      <td>1.489030e+10</td>\n",
       "      <td>1.481352e+10</td>\n",
       "      <td>179851249.0</td>\n",
       "      <td>179833897.0</td>\n",
       "      <td>179820708.0</td>\n",
       "      <td>179811932.0</td>\n",
       "      <td>179793126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11551</th>\n",
       "      <td>2024-04-26 07:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.360383</td>\n",
       "      <td>3.930057</td>\n",
       "      <td>151151.38884</td>\n",
       "      <td>253858.89276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.486836e+10</td>\n",
       "      <td>1.489030e+10</td>\n",
       "      <td>179852452.0</td>\n",
       "      <td>179851249.0</td>\n",
       "      <td>179833897.0</td>\n",
       "      <td>179820708.0</td>\n",
       "      <td>179811932.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11552 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID  target  _type  funding_rates  long_liquidations  \\\n",
       "0      2023-01-01 00:00:00     2.0  train       0.005049           0.012000   \n",
       "1      2023-01-01 01:00:00     1.0  train       0.005049           0.000000   \n",
       "2      2023-01-01 02:00:00     1.0  train       0.005049           0.000000   \n",
       "3      2023-01-01 03:00:00     1.0  train       0.005067           0.593000   \n",
       "4      2023-01-01 04:00:00     2.0  train       0.006210           0.361000   \n",
       "...                    ...     ...    ...            ...                ...   \n",
       "11547  2024-04-26 03:00:00     NaN   test            NaN           0.710000   \n",
       "11548  2024-04-26 04:00:00     NaN   test            NaN           6.577208   \n",
       "11549  2024-04-26 05:00:00     NaN   test            NaN           1.797163   \n",
       "11550  2024-04-26 06:00:00     NaN   test            NaN           0.803000   \n",
       "11551  2024-04-26 07:00:00     NaN   test            NaN           2.360383   \n",
       "\n",
       "       short_liquidations  long_liquidations_usd  short_liquidations_usd  \\\n",
       "0                0.000000              197.51610                 0.00000   \n",
       "1                0.712000                0.00000             11833.56104   \n",
       "2                0.000000                0.00000                 0.00000   \n",
       "3                0.000000             9754.76891                 0.00000   \n",
       "4                0.000000             5944.43714                 0.00000   \n",
       "...                   ...                    ...                     ...   \n",
       "11547            0.243500            45484.20433             15682.76464   \n",
       "11548            0.146000           420718.03779              9419.65430   \n",
       "11549            5.216490           114902.59095            337367.12807   \n",
       "11550            1.656000            51434.51531            106931.54104   \n",
       "11551            3.930057           151151.38884            253858.89276   \n",
       "\n",
       "       open_interest         close  ...  open_interest_1  open_interest_2  \\\n",
       "0       6.271344e+09  16536.747967  ...              NaN              NaN   \n",
       "1       6.288683e+09  16557.136536  ...     6.271344e+09              NaN   \n",
       "2       6.286796e+09  16548.149805  ...     6.288683e+09     6.271344e+09   \n",
       "3       6.284575e+09  16533.632875  ...     6.286796e+09     6.288683e+09   \n",
       "4       6.291582e+09  16524.712159  ...     6.284575e+09     6.286796e+09   \n",
       "...              ...           ...  ...              ...              ...   \n",
       "11547   1.486836e+10           NaN  ...     1.489030e+10     1.481352e+10   \n",
       "11548            NaN           NaN  ...     1.486836e+10     1.489030e+10   \n",
       "11549            NaN           NaN  ...              NaN     1.486836e+10   \n",
       "11550            NaN           NaN  ...              NaN              NaN   \n",
       "11551            NaN           NaN  ...              NaN              NaN   \n",
       "\n",
       "       open_interest_3  open_interest_4  open_interest_5  utxo_count_1  \\\n",
       "0                  NaN              NaN              NaN           NaN   \n",
       "1                  NaN              NaN              NaN    83308092.0   \n",
       "2                  NaN              NaN              NaN    83314883.0   \n",
       "3         6.271344e+09              NaN              NaN    83314090.0   \n",
       "4         6.288683e+09     6.271344e+09              NaN    83326258.0   \n",
       "...                ...              ...              ...           ...   \n",
       "11547     1.475586e+10     1.477917e+10     1.478950e+10   179811932.0   \n",
       "11548     1.481352e+10     1.475586e+10     1.477917e+10   179820708.0   \n",
       "11549     1.489030e+10     1.481352e+10     1.475586e+10   179833897.0   \n",
       "11550     1.486836e+10     1.489030e+10     1.481352e+10   179851249.0   \n",
       "11551              NaN     1.486836e+10     1.489030e+10   179852452.0   \n",
       "\n",
       "       utxo_count_2  utxo_count_3  utxo_count_4  utxo_count_5  \n",
       "0               NaN           NaN           NaN           NaN  \n",
       "1               NaN           NaN           NaN           NaN  \n",
       "2        83308092.0           NaN           NaN           NaN  \n",
       "3        83314883.0    83308092.0           NaN           NaN  \n",
       "4        83314090.0    83314883.0    83308092.0           NaN  \n",
       "...             ...           ...           ...           ...  \n",
       "11547   179793126.0   179753959.0   179728506.0   179718697.0  \n",
       "11548   179811932.0   179793126.0   179753959.0   179728506.0  \n",
       "11549   179820708.0   179811932.0   179793126.0   179753959.0  \n",
       "11550   179833897.0   179820708.0   179811932.0   179793126.0  \n",
       "11551   179851249.0   179833897.0   179820708.0   179811932.0  \n",
       "\n",
       "[11552 rows x 58 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 lasso 결과 가중치가 0으로 나온 피처들. 빼고 돌려보려면 이 블록을 주석해제할 것.\n",
    "omit_list = [\n",
    "    'funding_rates',\n",
    "    'taker_buy_ratio',\n",
    "    'taker_sell_ratio',\n",
    "    'taker_buy_sell_ratio',\n",
    "    'block_count',\n",
    "    'fees_block_mean',\n",
    "    'fees_total',\n",
    "    'fees_reward_percent',\n",
    "    'fees_transaction_mean',\n",
    "    'fees_transaction_mean_usd',\n",
    "    'fees_transaction_median',\n",
    "    'fees_transaction_median_usd',\n",
    "    'supply_new',\n",
    "    'tokens_transferred_median'\n",
    "]\n",
    "df.drop(omit_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usd로 측정된 피처는 중복이라고 판단해 빼보는 실험 블록.\n",
    "usd_list = [\n",
    "    \"long_liquidations_usd\",\n",
    "    \"short_liquidations_usd\",\n",
    "    \"fees_block_mean_usd\",\n",
    "    \"fees_total_usd\",\n",
    "    \"blockreward_usd\",\n",
    "    # \"fees_transaction_mean_usd\",      # omit_list와 중복되는 피처.\n",
    "    # \"fees_transaction_median_usd\",    # omit_list와 중복되는 피처.\n",
    "]\n",
    "df.drop(usd_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_list = [\n",
    "    \"tokens_transferred_mean\",\n",
    "    \"transactions_count_mean\"\n",
    "]\n",
    "df.drop(mean_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"difficulty\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _type에 따라 train, test 분리\n",
    "train_df = df.loc[df[\"_type\"]==\"train\"].drop(columns=[\"_type\"])\n",
    "test_df = df.loc[df[\"_type\"]==\"test\"].drop(columns=[\"_type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_to_class(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"close 변수를 target값으로 변환하는 함수입니다.\n",
    "\n",
    "    Args:\n",
    "        series (pd.Series): 변환을 원하는 close 변수\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: 변환된 target 값\n",
    "    \"\"\"\n",
    "    close = pd.DataFrame()\n",
    "    close[\"close\"] = series\n",
    "    close[\"close_lag1\"] = close[\"close\"].shift(1)\n",
    "    close[\"close_lag1_percent\"] = (close[\"close\"] - close[\"close_lag1\"]) / close[\"close_lag1\"]\n",
    "    close[\"class\"] = close[\"close\"]\n",
    "    for i in range(close.shape[0]):\n",
    "        if close.loc[i, \"close_lag1_percent\"] < -0.005:\n",
    "            close.loc[i, \"class\"] = 0\n",
    "        elif close.loc[i, \"close_lag1_percent\"] < 0:\n",
    "            close.loc[i, \"class\"] = 1\n",
    "        elif close.loc[i, \"close_lag1_percent\"] < 0.005:\n",
    "            close.loc[i, \"class\"] = 2\n",
    "        else:\n",
    "            close.loc[i, \"class\"] = 3\n",
    "            \n",
    "    return close[\"class\"].shift(-1).fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def model_train(\n",
    "    model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv: int = 5,\n",
    "    metric: str = \"accuracy\"\n",
    ") -> tuple[None, float]:\n",
    "    \"\"\"모델을 불러와 cross validation을 이용해 예측 성능을 확인하는 함수입니다.\n",
    "\n",
    "    Args:\n",
    "        model (Any): 학습을 수행할 모델\n",
    "        X_train (Any): 훈련 데이터 피처\n",
    "        y_train (Any): 훈련 데이터\n",
    "        cv (int): KFold 검정 횟수\n",
    "        metric (str): 성능 지표. accuracy(target), mae, mape mse 중 선택.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    kfold = KFold(n_splits=cv)\n",
    "    score_list = []\n",
    "    fold_model = []\n",
    "    for train_index, valid_index in kfold.split(X_train):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_valid, y_valid = X_train.iloc[valid_index], y_train.iloc[valid_index]\n",
    "\n",
    "        valid_target = X_valid[\"target\"]\n",
    "        X_train_fold.drop(\"target\", axis=1, inplace=True)\n",
    "        X_valid.drop(\"target\", axis=1, inplace=True)\n",
    "\n",
    "        # preprocessing\n",
    "        X_train_fold.fillna(X_train_fold.mean(), inplace=True)\n",
    "        y_train_fold.fillna(y_train_fold.mean(), inplace=True)\n",
    "        X_valid.fillna(X_valid.mean(), inplace=True)\n",
    "        y_valid.fillna(y_valid.mean(), inplace=True)\n",
    "\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        fold_model.append(model)\n",
    "\n",
    "        y_pred = model.predict(X_valid)\n",
    "        score = evaluate(valid_target, y_valid, y_pred, metric=metric)\n",
    "        score_list.append(score)\n",
    "    \n",
    "    return fold_model[np.argmax(score_list)], np.max(score_list)\n",
    "\n",
    "def evaluate(valid_target, y_valid, y_pred, metric):\n",
    "    if metric == 'accuracy':\n",
    "        classes = close_to_class(y_pred)\n",
    "        return accuracy_score(valid_target, classes)\n",
    "    if metric == 'mae':\n",
    "        return mean_absolute_error(y_valid, y_pred)\n",
    "    if metric == \"mse\":\n",
    "        return mean_squared_error(y_valid, y_pred)\n",
    "    if metric == \"mape\":\n",
    "        return mean_absolute_percentage_error(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(): 0.6421232876712328\n",
      "Ridge(alpha=20, random_state=42): 0.6421232876712328\n",
      "Lasso(alpha=20, max_iter=2000, random_state=42): 0.6626712328767124\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df.drop([\"ID\", \"close\"], axis=1)\n",
    "y_train = train_df[\"close\"]\n",
    "X_test = test_df.drop([\"ID\", \"close\"], axis=1)\n",
    "y_test = test_df[\"close\"]\n",
    "X_test.fillna(X_test.mean(), inplace=True)\n",
    "y_test.fillna(y_test.mean(), inplace=True)\n",
    "\n",
    "lr_reg = LinearRegression()\n",
    "ridge_reg = Ridge(alpha=20, random_state=42)\n",
    "lasso_reg = Lasso(alpha=20, max_iter=2000, random_state=42)\n",
    "lr_model, lr_score = model_train(lr_reg, X_train, y_train, cv=5, metric=\"accuracy\")\n",
    "ridge_model, ridge_score = model_train(ridge_reg, X_train, y_train, cv=5, metric=\"accuracy\")\n",
    "lasso_model, lasso_score = model_train(lasso_reg, X_train, y_train, cv=5, metric=\"accuracy\")\n",
    "print(f\"{lr_reg}: {lr_score}\")\n",
    "print(f\"{ridge_reg}: {ridge_score}\")\n",
    "print(f\"{lasso_reg}: {lasso_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference (Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr predict\n",
    "X_train_drop = fill_feature(X_train.drop(\"target\", axis=1), method=\"mean\")\n",
    "lasso_model.fit(X_train_drop, y_train)\n",
    "\n",
    "y_test_pred = lasso_model.predict(X_test.drop(\"target\", axis=1))\n",
    "y_test_pred_class = close_to_class(y_test_pred)\n",
    "\n",
    "pd.DataFrame(y_test_pred).to_csv(\"predicted_values_xgb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr output\n",
    "submission_df = submission_df.assign(target = y_test_pred_class)\n",
    "submission_df[\"target\"] = submission_df[\"target\"].astype(np.int8)\n",
    "submission_df.to_csv(\"output.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-lecture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
